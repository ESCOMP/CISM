Intel(R) Advisor can now assist with vectorization and show optimization
  report messages with your source code.
See "https://software.intel.com/en-us/intel-advisor-xe" for details.


    Report from: Interprocedural optimizations [ipo]

INLINING OPTION VALUES:
  -inline-factor: 100
  -inline-min-size: 30
  -inline-max-size: 230
  -inline-max-total-size: 2000
  -inline-max-per-routine: 10000
  -inline-max-per-compile: 500000


Begin optimization report for: cism_parallel._

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (cism_parallel._) [1] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(27,8)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(27,8):remark #34051: REGISTER ALLOCATION : [cism_parallel._] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:27

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    0[ reg_null]
        
    Routine temporaries
        Total         :       6
            Global    :       0
            Local     :       6
        Regenerable   :       0
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_CHARACTER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_CHARACTER) [2] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(396,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(396,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_character_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:396

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      26
            Global    :       9
            Local     :      17
        Regenerable   :      11
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       3 [7.14e+00 ~ 7.1%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_INTEGER) [3] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(418,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(418,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:418

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      24
            Global    :       8
            Local     :      16
        Regenerable   :      11
        Spilled       :       0
        
    Routine stack
        Variables     :       8 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       2 [4.35e+00 ~ 4.3%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_INTEGER_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_INTEGER_1D) [4] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(439,14)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(439,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_integer_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:439

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      73
            Global    :      36
            Local     :      37
        Regenerable   :      12
        Spilled       :       5
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       3 [1.89e+00 ~ 1.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_LOGICAL

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_LOGICAL) [5] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(460,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(460,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_logical_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:460

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      24
            Global    :       8
            Local     :      16
        Regenerable   :      11
        Spilled       :       0
        
    Routine stack
        Variables     :       8 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       2 [4.35e+00 ~ 4.3%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_LOGICAL_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_LOGICAL_1D) [6] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(481,14)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(481,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_logical_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:481

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      73
            Global    :      36
            Local     :      37
        Regenerable   :      12
        Spilled       :       5
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       3 [1.89e+00 ~ 1.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_REAL4) [7] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(502,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(502,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:502

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      24
            Global    :       8
            Local     :      16
        Regenerable   :      11
        Spilled       :       0
        
    Routine stack
        Variables     :       8 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       2 [4.35e+00 ~ 4.3%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_REAL4_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_REAL4_1D) [8] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(523,14)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(523,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_real4_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:523

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      73
            Global    :      36
            Local     :      37
        Regenerable   :      12
        Spilled       :       5
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       3 [1.89e+00 ~ 1.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_REAL8) [9] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(544,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(544,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:544

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      24
            Global    :       8
            Local     :      16
        Regenerable   :      11
        Spilled       :       0
        
    Routine stack
        Variables     :       8 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       2 [4.35e+00 ~ 4.3%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::BROADCAST_REAL8_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::BROADCAST_REAL8_1D) [10] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(565,14)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(565,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_broadcast_real8_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:565

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   14[ rax rdx rcx rbx rsi rdi r8-r10 r12-r15 zmm0]
        
    Routine temporaries
        Total         :      64
            Global    :      30
            Local     :      34
        Regenerable   :      12
        Spilled       :       5
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       3 [1.55e+00 ~ 1.5%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_EXECUTION

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_EXECUTION) [11] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(587,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(587,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_execution_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:587

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    1[ rax]
        
    Routine temporaries
        Total         :       7
            Global    :       0
            Local     :       7
        Regenerable   :       1
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_INTEGER_2D) [12] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(611,14)
  -> INLINE: (646,13) CISM_PARALLEL::PARALLEL_STOP
  -> (664,10) CISM_PARALLEL::FC_GATHER_INT
  -> CP_CLONE (700,10) CISM_PARALLEL::FC_GATHERV_INT..0


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(678,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(678,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(678,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(678,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(681,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(681,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(684,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (685:11) and DISPLS(i) (685:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(684,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(699,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(699,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(699,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(699,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(699,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(699,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(703,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(678,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(704,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(611,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_var_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:611

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1039
            Global    :     161
            Local     :     878
        Regenerable   :     130
        Spilled       :      42
        
    Routine stack
        Variables     :     584 bytes*
            Reads     :      39 [1.07e+00 ~ 1.1%]
            Writes    :     118 [3.02e+00 ~ 3.0%]
        Spills        :     280 bytes*
            Reads     :      58 [4.89e+00 ~ 4.9%]
            Writes    :      39 [1.49e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::FC_GATHER_INT

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::FC_GATHER_INT) [13] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9397,14)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9477,10)
   remark #25399: memcopy generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9477,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9477,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9473,10)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9484,10)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9477,10):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9397,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_fc_gather_int_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9397

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     133
            Global    :      43
            Local     :      90
        Regenerable   :      48
        Spilled       :      13
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       5 [6.45e-01 ~ 0.6%]
            Writes    :       6 [9.15e-01 ~ 0.9%]
        Spills        :      64 bytes*
            Reads     :      12 [2.26e+00 ~ 2.3%]
            Writes    :      10 [1.46e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::FC_GATHERV_INT..0

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::FC_GATHERV_INT..0) [14] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9527,15)
  CLONED FROM: CISM_PARALLEL::FC_GATHERV_INT(X,X,X,X,X,X,X,X,X,0x00000000,0x00000000)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9608,10)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9608,10)
<Remainder loop for vectorization>
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9604,10)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9615,10)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9527,15):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_fc_gatherv_int_..0] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9527

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     131
            Global    :      44
            Local     :      87
        Regenerable   :      48
        Spilled       :      14
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       4 [5.93e-01 ~ 0.6%]
            Writes    :       5 [9.67e-01 ~ 1.0%]
        Spills        :      72 bytes*
            Reads     :      13 [2.63e+00 ~ 2.6%]
            Writes    :       9 [1.33e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_LOGICAL_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_LOGICAL_2D) [15] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(718,14)
  -> INLINE: (753,13) CISM_PARALLEL::PARALLEL_STOP
  -> (771,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (807,10) CISM_PARALLEL::FC_GATHERV_LOG


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(785,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(785,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(785,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(785,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(788,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(788,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(791,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (792:11) and DISPLS(i) (792:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(791,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(806,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(806,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(806,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(806,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(806,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(806,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10007,10) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(807,10)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10007,10) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(807,10)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(810,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10003,10) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(807,10)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10014,10) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(807,10)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(785,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(811,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(718,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_var_logical_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:718

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1133
            Global    :     188
            Local     :     945
        Regenerable   :     180
        Spilled       :      44
        
    Routine stack
        Variables     :     608 bytes*
            Reads     :      48 [1.10e+00 ~ 1.1%]
            Writes    :     123 [2.92e+00 ~ 2.9%]
        Spills        :     296 bytes*
            Reads     :      63 [4.66e+00 ~ 4.7%]
            Writes    :      43 [1.44e+00 ~ 1.4%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_REAL4_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_REAL4_2D) [16] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(825,14)
  -> INLINE: (860,13) CISM_PARALLEL::PARALLEL_STOP
  -> (878,10) CISM_PARALLEL::FC_GATHER_INT
  -> (914,10) CISM_PARALLEL::FC_GATHERV_REAL4


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(892,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(892,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(892,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(892,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(895,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(895,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(898,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (899:11) and DISPLS(i) (899:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(898,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(913,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(913,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(913,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(913,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(913,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(913,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(917,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(892,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(918,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(825,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_var_real4_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:825

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1046
            Global    :     166
            Local     :     880
        Regenerable   :     132
        Spilled       :      45
        
    Routine stack
        Variables     :     584 bytes*
            Reads     :      39 [1.05e+00 ~ 1.1%]
            Writes    :     118 [2.95e+00 ~ 3.0%]
        Spills        :     304 bytes*
            Reads     :      62 [4.96e+00 ~ 5.0%]
            Writes    :      42 [1.78e+00 ~ 1.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::FC_GATHERV_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::FC_GATHERV_REAL4) [17] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9660,15)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9741,10)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9741,10)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9764,34)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9764,34)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9764,34)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9764,34)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9764,44)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9764,44)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9764,44)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9764,44)
<Remainder, Multiversioned v2>
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9737,10)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9748,10)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9660,15):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_fc_gatherv_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9660

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     196
            Global    :      78
            Local     :     118
        Regenerable   :      53
        Spilled       :      16
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       4 [4.63e-01 ~ 0.5%]
            Writes    :       5 [7.54e-01 ~ 0.8%]
        Spills        :      88 bytes*
            Reads     :      14 [2.49e+00 ~ 2.5%]
            Writes    :      12 [1.28e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_REAL4_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_REAL4_3D) [18] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(932,14)
  -> INLINE: (968,13) CISM_PARALLEL::PARALLEL_STOP
  -> (986,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (1005,16) CISM_PARALLEL::PARALLEL_STOP
  -> (1038,10) CISM_PARALLEL::FC_GATHERV_REAL4


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1014,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1014,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1014,8)
         remark #25408: memset generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1014,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1014,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1017,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1017,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1021,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1022:11) and DISPLS(i) (1022:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1021,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1037,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1037,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1037,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1037,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1037,5)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1037,5)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1037,5)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1041,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11)
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11)
            remark #25399: memcopy generated
            remark #15542: loop was not vectorized: inner loop was already vectorized

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11)
               remark #15300: LOOP WAS VECTORIZED
            LOOP END

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11)
            <Remainder loop for vectorization>
            LOOP END
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1014,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1042,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(932,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_var_real4_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:932

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1144
            Global    :     188
            Local     :     956
        Regenerable   :     181
        Spilled       :      72
        
    Routine stack
        Variables     :     748 bytes*
            Reads     :      39 [3.02e-01 ~ 0.3%]
            Writes    :     135 [9.18e-01 ~ 0.9%]
        Spills        :     528 bytes*
            Reads     :     124 [6.39e+00 ~ 6.4%]
            Writes    :      93 [3.48e+00 ~ 3.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_REAL8_2D) [19] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1058,14)
  -> INLINE: (1093,13) CISM_PARALLEL::PARALLEL_STOP
  -> (1111,10) CISM_PARALLEL::FC_GATHER_INT
  -> (1148,10) CISM_PARALLEL::FC_GATHERV_REAL8


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1125,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1125,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1125,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1125,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1128,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1128,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1131,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1132:11) and DISPLS(i) (1132:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1131,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1147,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1147,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1147,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1147,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1147,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1147,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1151,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1125,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1152,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1058,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_var_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:1058

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1025
            Global    :     153
            Local     :     872
        Regenerable   :     132
        Spilled       :      37
        
    Routine stack
        Variables     :     584 bytes*
            Reads     :      37 [9.81e-01 ~ 1.0%]
            Writes    :     118 [2.86e+00 ~ 2.9%]
        Spills        :     248 bytes*
            Reads     :      51 [4.25e+00 ~ 4.2%]
            Writes    :      37 [1.62e+00 ~ 1.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::FC_GATHERV_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::FC_GATHERV_REAL8) [20] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9793,15)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9874,10)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9874,10)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9897,34)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9897,34)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9897,34)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9897,34)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9897,44)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9897,44)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9897,44)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9897,44)
<Remainder, Multiversioned v2>
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9870,10)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9881,10)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9793,15):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_fc_gatherv_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9793

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     197
            Global    :      78
            Local     :     119
        Regenerable   :      54
        Spilled       :      16
        
    Routine stack
        Variables     :      28 bytes*
            Reads     :       4 [4.61e-01 ~ 0.5%]
            Writes    :       5 [7.51e-01 ~ 0.8%]
        Spills        :      88 bytes*
            Reads     :      14 [2.48e+00 ~ 2.5%]
            Writes    :      12 [1.27e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_REAL8_3D) [21] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1166,14)
  -> INLINE: (1202,13) CISM_PARALLEL::PARALLEL_STOP
  -> (1220,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (1239,16) CISM_PARALLEL::PARALLEL_STOP
  -> (1272,10) CISM_PARALLEL::FC_GATHERV_REAL8


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1248,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1248,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1248,8)
         remark #25408: memset generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1248,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1248,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1251,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1251,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1255,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1256:11) and DISPLS(i) (1256:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1255,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1271,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1271,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1271,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1271,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1271,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1271,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1271,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1275,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11)
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11)
            remark #25399: memcopy generated
            remark #15542: loop was not vectorized: inner loop was already vectorized

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11)
               remark #15300: LOOP WAS VECTORIZED
            LOOP END

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11)
            <Remainder loop for vectorization>
            LOOP END
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1248,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1276,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1166,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_var_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:1166

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1136
            Global    :     181
            Local     :     955
        Regenerable   :     181
        Spilled       :      70
        
    Routine stack
        Variables     :     748 bytes*
            Reads     :      39 [2.86e-01 ~ 0.3%]
            Writes    :     135 [8.72e-01 ~ 0.9%]
        Spills        :     512 bytes*
            Reads     :     117 [5.79e+00 ~ 5.8%]
            Writes    :      92 [3.35e+00 ~ 3.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_ROW_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_ROW_REAL8_2D) [22] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1295,14)
  -> INLINE: (1335,13) CISM_PARALLEL::PARALLEL_STOP
  -> (1412,10) CISM_PARALLEL::FC_GATHERV_REAL8


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1386,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1386,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1386,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1386,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1389,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1389,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1392,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1393:11) and DISPLS(i) (1393:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1392,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1412,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1412,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1412,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1412,10)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1412,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1412,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1416,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1386,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1417,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1295,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_var_row_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:1295

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     979
            Global    :     152
            Local     :     827
        Regenerable   :     146
        Spilled       :      39
        
    Routine stack
        Variables     :     604 bytes*
            Reads     :      30 [8.33e-01 ~ 0.8%]
            Writes    :     110 [2.93e+00 ~ 2.9%]
        Spills        :     264 bytes*
            Reads     :      65 [4.72e+00 ~ 4.7%]
            Writes    :      42 [1.67e+00 ~ 1.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_ALL_VAR_ROW_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_ALL_VAR_ROW_REAL8_2D) [23] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1434,14)
  -> INLINE: (1477,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1514,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1514,5)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1514,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1514,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1517,5)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1517,5)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1520,5)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1521:8) and DISPLS(i) (1521:8)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1520,5)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1535,25)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1535,25)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1535,25)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1535,25)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1535,25)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1535,25)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1539,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1514,5):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1540,8):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1434,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_all_var_row_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:1434

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     845
            Global    :     146
            Local     :     699
        Regenerable   :     130
        Spilled       :      42
        
    Routine stack
        Variables     :     604 bytes*
            Reads     :      28 [5.58e-01 ~ 0.6%]
            Writes    :      89 [1.67e+00 ~ 1.7%]
        Spills        :     288 bytes*
            Reads     :      70 [5.92e+00 ~ 5.9%]
            Writes    :      44 [1.65e+00 ~ 1.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_COL_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_VAR_COL_REAL8_2D) [24] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1556,14)
  -> INLINE: (1596,13) CISM_PARALLEL::PARALLEL_STOP
  -> (1674,10) CISM_PARALLEL::FC_GATHERV_REAL8


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1648,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1648,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1648,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1648,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1651,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1651,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1654,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1655:11) and DISPLS(i) (1655:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1654,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1674,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1674,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1674,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1674,10)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1674,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1674,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1678,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1648,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1679,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1556,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_var_col_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:1556

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     979
            Global    :     152
            Local     :     827
        Regenerable   :     146
        Spilled       :      39
        
    Routine stack
        Variables     :     604 bytes*
            Reads     :      30 [8.33e-01 ~ 0.8%]
            Writes    :     110 [2.93e+00 ~ 2.9%]
        Spills        :     264 bytes*
            Reads     :      65 [4.72e+00 ~ 4.7%]
            Writes    :      42 [1.67e+00 ~ 1.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GATHER_ALL_VAR_COL_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GATHER_ALL_VAR_COL_REAL8_2D) [25] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1696,14)
  -> INLINE: (1736,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1773,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1773,5)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1773,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1773,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1776,5)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1776,5)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1779,5)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1780:8) and DISPLS(i) (1780:8)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1779,5)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1794,25)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1794,25)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1794,25)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1794,25)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1794,25)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1794,25)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1798,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1773,5):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1799,8):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1696,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_gather_all_var_col_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:1696

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     845
            Global    :     146
            Local     :     699
        Regenerable   :     130
        Spilled       :      42
        
    Routine stack
        Variables     :     604 bytes*
            Reads     :      28 [5.58e-01 ~ 0.6%]
            Writes    :      89 [1.67e+00 ~ 1.7%]
        Spills        :     288 bytes*
            Reads     :      70 [5.92e+00 ~ 5.9%]
            Writes    :      44 [1.65e+00 ~ 1.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GET_VAR_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GET_VAR_INTEGER_2D) [26] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1817,12)
  -> INLINE: (1857,13) CISM_PARALLEL::PARALLEL_STOP
  -> (1868,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (1897,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1876,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1876,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1876,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1876,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1881,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1881,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1883,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1884:11) and DISPLS(i) (1884:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1883,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1887,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1901,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1901,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1901,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1901,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1901,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1901,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1876,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1888,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1817,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_get_var_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:1817

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     993
            Global    :     149
            Local     :     844
        Regenerable   :     134
        Spilled       :      43
        
    Routine stack
        Variables     :     792 bytes*
            Reads     :      63 [1.60e+00 ~ 1.6%]
            Writes    :     185 [5.04e+00 ~ 5.0%]
        Spills        :     280 bytes*
            Reads     :      60 [5.06e+00 ~ 5.1%]
            Writes    :      43 [1.80e+00 ~ 1.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL4_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL4_1D) [27] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1909,12)
  -> INLINE: (1949,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (1950,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (1960,13) CISM_PARALLEL::PARALLEL_STOP
  -> (1962,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (1992,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1972,8)
   remark #25408: memset generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1972,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1972,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1977,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1977,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1979,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (1980:11) and DISPLS(i) (1980:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1979,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1983,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1984,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1984,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1984,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1994,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1994,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1994,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1994,10)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1994,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1994,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1994,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1994,10)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1972,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1984,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(1909,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_get_var_real4_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:1909

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     877
            Global    :     127
            Local     :     750
        Regenerable   :     172
        Spilled       :      13
        
    Routine stack
        Variables     :     672 bytes*
            Reads     :      54 [3.45e+00 ~ 3.4%]
            Writes    :     151 [7.99e+00 ~ 8.0%]
        Spills        :      64 bytes*
            Reads     :      10 [1.92e+00 ~ 1.9%]
            Writes    :       8 [6.98e-01 ~ 0.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL4_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL4_2D) [28] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2002,12)
  -> INLINE: (2042,13) CISM_PARALLEL::PARALLEL_STOP
  -> (2053,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (2082,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2061,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2061,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2061,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2061,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2066,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2066,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2068,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (2069:11) and DISPLS(i) (2069:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2068,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2072,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2086,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2086,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2086,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2086,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2086,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2086,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2061,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2073,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2002,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_get_var_real4_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:2002

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     999
            Global    :     153
            Local     :     846
        Regenerable   :     136
        Spilled       :      44
        
    Routine stack
        Variables     :     792 bytes*
            Reads     :      63 [1.58e+00 ~ 1.6%]
            Writes    :     185 [4.99e+00 ~ 5.0%]
        Spills        :     296 bytes*
            Reads     :      65 [5.14e+00 ~ 5.1%]
            Writes    :      45 [1.85e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL8_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL8_1D) [29] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2094,12)
  -> INLINE: (2134,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (2135,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (2145,13) CISM_PARALLEL::PARALLEL_STOP
  -> (2147,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (2177,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2157,8)
   remark #25408: memset generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2157,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2157,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2162,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2162,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2164,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (2165:11) and DISPLS(i) (2165:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2164,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2168,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2169,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2169,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2169,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2179,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2179,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2179,10)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2179,10)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2179,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2179,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2179,10)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2179,10)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2157,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2169,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2094,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_get_var_real8_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:2094

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     869
            Global    :     121
            Local     :     748
        Regenerable   :     173
        Spilled       :      13
        
    Routine stack
        Variables     :     672 bytes*
            Reads     :      54 [3.37e+00 ~ 3.4%]
            Writes    :     151 [7.82e+00 ~ 7.8%]
        Spills        :      64 bytes*
            Reads     :      16 [1.95e+00 ~ 2.0%]
            Writes    :       8 [6.18e-01 ~ 0.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL8_2D) [30] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2187,12)
  -> INLINE: (2227,13) CISM_PARALLEL::PARALLEL_STOP
  -> (2238,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (2268,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2247,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2247,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2247,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2247,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2252,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2252,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2254,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (2255:11) and DISPLS(i) (2255:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2254,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2258,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2272,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2272,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2272,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2272,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2272,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2272,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2247,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2259,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2187,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_get_var_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:2187

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     987
            Global    :     146
            Local     :     841
        Regenerable   :     136
        Spilled       :      39
        
    Routine stack
        Variables     :     792 bytes*
            Reads     :      63 [1.52e+00 ~ 1.5%]
            Writes    :     185 [4.78e+00 ~ 4.8%]
        Spills        :     256 bytes*
            Reads     :      63 [4.51e+00 ~ 4.5%]
            Writes    :      41 [1.57e+00 ~ 1.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GET_VAR_REAL8_3D) [31] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2280,12)
  -> INLINE: (2320,13) CISM_PARALLEL::PARALLEL_STOP
  -> (2331,10) CISM_PARALLEL::FC_GATHER_INT
  -> INLINE: (2362,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2340,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2340,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2340,8)
         remark #25408: memset generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2340,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2340,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2345,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2345,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2348,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (2349:11) and DISPLS(i) (2349:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2348,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2352,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11)
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11)
            remark #25399: memcopy generated
            remark #15542: loop was not vectorized: inner loop was already vectorized

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11)
               remark #15300: LOOP WAS VECTORIZED
            LOOP END

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11)
            <Remainder loop for vectorization>
            LOOP END
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2366,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2366,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2366,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2366,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2366,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2366,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2366,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2340,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2353,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2280,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_get_var_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:2280

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1048
            Global    :     176
            Local     :     872
        Regenerable   :     136
        Spilled       :      71
        
    Routine stack
        Variables     :     864 bytes*
            Reads     :      69 [3.20e-01 ~ 0.3%]
            Writes    :     200 [8.36e-01 ~ 0.8%]
        Spills        :     512 bytes*
            Reads     :     117 [8.02e+00 ~ 8.0%]
            Writes    :      84 [2.37e+00 ~ 2.4%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GRID

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GRID) [32] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2375,14)
  -> INLINE: (2458,16) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (2477,19) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (2506,33) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (2554,26) CISM_PARALLEL::PARALLEL_REDUCE_MIN_INTEGER
  -> INLINE: (2555,26) CISM_PARALLEL::PARALLEL_REDUCE_MAX_INTEGER
  -> INLINE: (2556,26) CISM_PARALLEL::PARALLEL_REDUCE_MIN_INTEGER
  -> INLINE: (2557,26) CISM_PARALLEL::PARALLEL_REDUCE_MAX_INTEGER
  -> INLINE: (2607,14) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (2612,14) CISM_PARALLEL::PARALLEL_STOP
  -> (2631,10) CISM_PARALLEL::DISTRIBUTED_PRINT_GRID


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2495,5)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed ANTI dependence between global_nsn (2497:25) and nstasks (2502:14)
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2522,5)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2533,5)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2375,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_grid_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:2375

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   17[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm2]
        
    Routine temporaries
        Total         :     654
            Global    :     124
            Local     :     530
        Regenerable   :     367
        Spilled       :      25
        
    Routine stack
        Variables     :     916 bytes*
            Reads     :       4 [5.48e-01 ~ 0.5%]
            Writes    :      77 [8.39e-01 ~ 0.8%]
        Spills        :     160 bytes*
            Reads     :      30 [7.09e+00 ~ 7.1%]
            Writes    :      22 [2.35e+00 ~ 2.4%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PRINT_GRID

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PRINT_GRID) [33] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3287,14)
  -> INLINE: (3308,10) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9477,10) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3308,10)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between recvbuf(displs+i) (9478:13) and mybounds(i) (9478:13)
   remark #25436: completely unrolled by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3310,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3314,14)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3314,14)
   <Remainder>
   LOOP END
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9473,10) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3308,10)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9484,10) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3308,10)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3287,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_print_grid_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3287

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   14[ rax rdx rcx rbx rsi rdi r8-r15]
        
    Routine temporaries
        Total         :     262
            Global    :      61
            Local     :     201
        Regenerable   :     111
        Spilled       :      14
        
    Routine stack
        Variables     :     248 bytes*
            Reads     :      12 [1.16e+00 ~ 1.2%]
            Writes    :      38 [6.83e+00 ~ 6.8%]
        Spills        :      80 bytes*
            Reads     :      20 [6.62e+00 ~ 6.6%]
            Writes    :      13 [2.24e+00 ~ 2.2%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_GRID_ACTIVE_BLOCKS

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_GRID_ACTIVE_BLOCKS) [34] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2639,14)
  -> (2792,13) CISM_PARALLEL::PARALLEL_STOP
  -> (2989,16) CISM_PARALLEL::PARALLEL_STOP
  -> (2996,19) CISM_PARALLEL::PARALLEL_STOP
  -> (3002,19) CISM_PARALLEL::PARALLEL_STOP
  -> (3038,19) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (3070,10) CISM_PARALLEL::BROADCAST_LOGICAL_1D
  -> (3217,14) CISM_PARALLEL::PARALLEL_STOP
  -> (3222,14) CISM_PARALLEL::PARALLEL_STOP
  -> (3226,10) CISM_PARALLEL::PARALLEL_BARRIER
  -> (3246,10) CISM_PARALLEL::DISTRIBUTED_PRINT_GRID


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2927,26)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2927,26)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2928,26)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2928,26)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2929,26)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2929,26)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2930,26)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2930,26)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2946,5)
   remark #25408: memset generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2946,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2946,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2952,14)
   remark #15520: loop was not vectorized: loop with multiple exits cannot be vectorized unless it meets search loop idiom criteria   [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2953,42) ]
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2966,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2967,14)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (2969:17) and at (2969:17)
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2975,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2976,14)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (2978:17) and at (2978:17)
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3016,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3018,14)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3018,14)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3018,14)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3020,14)
      remark #15520: loop was not vectorized: loop with multiple exits cannot be vectorized unless it meets search loop idiom criteria   [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3027,42) ]
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3032,14)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3032,14)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3032,14)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3045,14)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3046,17)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3048:20) and at (3048:20)
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3055,17)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3055,17)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3057:20) and at (3057:20)
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3070,10)
   remark #25399: memcopy generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3070,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3070,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3070,10)
   remark #25399: memcopy generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3070,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3070,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3077,5)
   remark #25408: memset generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3077,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3077,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3078,5)
   remark #25408: memset generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3078,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3078,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3095,14)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed ANTI dependence between nt (3083:11) and nt (3083:11)
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3095,14)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3092,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3093,11)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3095:14) and at (3095:14)
   LOOP END
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2923,5)
   remark #15536: loop was not vectorized: inner loop throttling prevents vectorization of this outer loop. Refer to inner loop message for more details.   [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2866,8) ]

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2866,8)
      remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2879,8)
      remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2960,8)
   remark #15536: loop was not vectorized: inner loop throttling prevents vectorization of this outer loop. Refer to inner loop message for more details.   [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2959,11) ]

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2959,11)
      remark #15522: loop was not vectorized: loop control flow is too complex. Try using canonical loop form from OpenMP specification
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2946,5):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3018,14):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3032,14):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(497,20):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3077,5):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3078,5):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(2639,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_grid_active_blocks_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:2639

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   18[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm3]
        
    Routine temporaries
        Total         :    3263
            Global    :     394
            Local     :    2869
        Regenerable   :     842
        Spilled       :     107
        
    Routine stack
        Variables     :    2948 bytes*
            Reads     :     191 [1.93e+00 ~ 1.9%]
            Writes    :     610 [8.41e+00 ~ 8.4%]
        Spills        :     816 bytes*
            Reads     :     221 [7.23e+00 ~ 7.2%]
            Writes    :     144 [2.53e+00 ~ 2.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_BARRIER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_BARRIER) [35] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5021,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5021,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_barrier_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5021

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    2[ rsi rdi]
        
    Routine temporaries
        Total         :      10
            Global    :       6
            Local     :       4
        Regenerable   :       4
        Spilled       :       0
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_ISPARALLEL

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_ISPARALLEL) [36] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3254,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3254,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_isparallel_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3254

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    1[ rax]
        
    Routine temporaries
        Total         :       7
            Global    :       0
            Local     :       7
        Regenerable   :       1
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_OWNER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_OWNER) [37] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3265,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3265,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_owner_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3265

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rsi rdi r8-r11]
        
    Routine temporaries
        Total         :      35
            Global    :       0
            Local     :      35
        Regenerable   :       1
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PRINT_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PRINT_INTEGER_2D) [38] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3334,14)
  -> INLINE: (3370,13) CISM_PARALLEL::PARALLEL_STOP
  -> (3382,10) CISM_PARALLEL::FC_GATHER_INT
  -> CP_CLONE (3407,10) CISM_PARALLEL::FC_GATHERV_INT..0


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3391,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3391,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3391,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3391,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3394,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3394,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3396,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (3397:11) and DISPLS(i) (3397:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3396,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3406,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3406,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3406,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3406,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3406,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3406,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3410,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3418,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3419,14)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3420:17) and at (3420:17)
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3425,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3426,14)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3427:17) and at (3427:17)
   LOOP END
LOOP END

Fusion of IFs performed in cism_parallel_mp_distributed_print_integer_2d_ at line 3419

Fusion of IFs performed in cism_parallel_mp_distributed_print_integer_2d_ at line 3426

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3391,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3411,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3334,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_print_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3334

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1173
            Global    :     218
            Local     :     955
        Regenerable   :     218
        Spilled       :      58
        
    Routine stack
        Variables     :     944 bytes*
            Reads     :      72 [1.31e+00 ~ 1.3%]
            Writes    :     206 [6.01e+00 ~ 6.0%]
        Spills        :     400 bytes*
            Reads     :      90 [5.81e+00 ~ 5.8%]
            Writes    :      67 [1.66e+00 ~ 1.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PRINT_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PRINT_REAL8_2D) [39] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3441,14)
  -> INLINE: (3477,13) CISM_PARALLEL::PARALLEL_STOP
  -> (3489,10) CISM_PARALLEL::FC_GATHER_INT
  -> (3514,10) CISM_PARALLEL::FC_GATHERV_REAL8


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3498,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3498,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3498,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3498,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3501,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3501,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3503,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (3504:11) and DISPLS(i) (3504:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3503,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3513,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3513,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3513,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3513,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3513,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3513,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3517,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3525,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3526,14)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3527:17) and at (3527:17)
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3532,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3533,14)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3534:17) and at (3534:17)
   LOOP END
LOOP END

Fusion of IFs performed in cism_parallel_mp_distributed_print_real8_2d_ at line 3526

Fusion of IFs performed in cism_parallel_mp_distributed_print_real8_2d_ at line 3533

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3498,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3518,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3441,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_print_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3441

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1159
            Global    :     210
            Local     :     949
        Regenerable   :     220
        Spilled       :      55
        
    Routine stack
        Variables     :     944 bytes*
            Reads     :      70 [1.22e+00 ~ 1.2%]
            Writes    :     206 [5.76e+00 ~ 5.8%]
        Spills        :     360 bytes*
            Reads     :      88 [5.11e+00 ~ 5.1%]
            Writes    :      69 [1.58e+00 ~ 1.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PRINT_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PRINT_REAL8_3D) [40] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3548,14)
  -> (3584,13) CISM_PARALLEL::PARALLEL_STOP
  -> (3596,10) CISM_PARALLEL::FC_GATHER_INT
  -> (3622,10) CISM_PARALLEL::FC_GATHERV_REAL8


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3605,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3605,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3605,8)
         remark #25408: memset generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3605,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3605,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3608,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3608,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3610,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (3611:11) and DISPLS(i) (3611:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3610,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3620,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3620,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3620,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3620,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3620,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3620,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3620,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3621,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3621,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3621,5)
         remark #25401: memcopy(with guard) generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3621,5)
         <Multiversioned v2>
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3621,5)
         <Remainder loop for vectorization, Multiversioned v2>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3625,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11)
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11)
            remark #25399: memcopy generated
            remark #15542: loop was not vectorized: inner loop was already vectorized

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11)
               remark #15300: LOOP WAS VECTORIZED
            LOOP END

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11)
            <Remainder loop for vectorization>
            LOOP END
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3633,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3634,14)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3635:17) and at (3635:17)
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3640,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3641,14)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (3642:17) and at (3642:17)
   LOOP END
LOOP END

Fusion of IFs performed in cism_parallel_mp_distributed_print_real8_3d_ at line 3634

Fusion of IFs performed in cism_parallel_mp_distributed_print_real8_3d_ at line 3641

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3605,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3621,5):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3626,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3548,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_print_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3548

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1213
            Global    :     250
            Local     :     963
        Regenerable   :     191
        Spilled       :      93
        
    Routine stack
        Variables     :    1028 bytes*
            Reads     :      79 [4.46e-01 ~ 0.4%]
            Writes    :     230 [2.48e+00 ~ 2.5%]
        Spills        :     704 bytes*
            Reads     :     163 [6.01e+00 ~ 6.0%]
            Writes    :     121 [2.52e+00 ~ 2.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PUT_VAR_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PUT_VAR_INTEGER_2D) [41] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3659,12)
  -> INLINE: (3685,19) CISM_PARALLEL::GET_BOUNDS_INFO
    -> INLINE: (4999,13) CISM_PARALLEL::PARALLEL_STOP
  -> (3696,10) CISM_PARALLEL::FC_GATHER_INT
  -> CP_CLONE (3722,10) CISM_PARALLEL::FC_GATHERV_INT..0
  -> INLINE: (3733,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3705,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3705,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3705,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3705,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3708,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3708,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3710,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (3711:11) and DISPLS(i) (3711:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3710,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3720,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3720,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3720,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3720,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3720,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3720,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3730,41)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3705,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3726,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3659,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_put_var_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3659

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1052
            Global    :     175
            Local     :     877
        Regenerable   :     132
        Spilled       :      47
        
    Routine stack
        Variables     :     788 bytes*
            Reads     :      63 [1.41e+00 ~ 1.4%]
            Writes    :     185 [4.79e+00 ~ 4.8%]
        Spills        :     336 bytes*
            Reads     :      68 [5.26e+00 ~ 5.3%]
            Writes    :      49 [1.56e+00 ~ 1.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL4_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL4_1D) [42] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3741,12)
  -> INLINE: (3781,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (3782,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (3783,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (3784,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (3802,13) CISM_PARALLEL::PARALLEL_STOP
  -> (3804,10) CISM_PARALLEL::FC_GATHER_INT
  -> (3832,10) CISM_PARALLEL::FC_GATHERV_REAL4
  -> INLINE: (3847,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3818,8)
   remark #25408: memset generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3818,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3818,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3821,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3821,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3823,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (3824:11) and DISPLS(i) (3824:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3823,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3832,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3832,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3832,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3832,10)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3841,13)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3836,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3836,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3836,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3818,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3836,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3741,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_put_var_real4_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3741

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1019
            Global    :     125
            Local     :     894
        Regenerable   :     217
        Spilled       :      14
        
    Routine stack
        Variables     :     780 bytes*
            Reads     :      62 [3.94e+00 ~ 3.9%]
            Writes    :     178 [1.01e+01 ~ 10.1%]
        Spills        :      72 bytes*
            Reads     :      11 [1.09e+00 ~ 1.1%]
            Writes    :      12 [5.72e-01 ~ 0.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL4_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL4_2D) [43] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3855,12)
  -> INLINE: (3881,19) CISM_PARALLEL::GET_BOUNDS_INFO
    -> INLINE: (4999,13) CISM_PARALLEL::PARALLEL_STOP
  -> (3892,10) CISM_PARALLEL::FC_GATHER_INT
  -> (3917,10) CISM_PARALLEL::FC_GATHERV_REAL4
  -> INLINE: (3928,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3900,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3900,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3900,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3900,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3903,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3903,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3905,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (3906:11) and DISPLS(i) (3906:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3905,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3915,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3915,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3915,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3915,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3915,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3915,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3925,39)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3900,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3921,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3855,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_put_var_real4_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3855

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1048
            Global    :     179
            Local     :     869
        Regenerable   :     134
        Spilled       :      51
        
    Routine stack
        Variables     :     788 bytes*
            Reads     :      63 [1.40e+00 ~ 1.4%]
            Writes    :     185 [4.77e+00 ~ 4.8%]
        Spills        :     360 bytes*
            Reads     :      72 [5.33e+00 ~ 5.3%]
            Writes    :      52 [1.71e+00 ~ 1.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL8_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL8_1D) [44] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3936,12)
  -> INLINE: (3977,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (3978,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (3979,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (3980,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (3998,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4000,10) CISM_PARALLEL::FC_GATHER_INT
  -> (4028,10) CISM_PARALLEL::FC_GATHERV_REAL8
  -> INLINE: (4043,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4014,8)
   remark #25408: memset generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4014,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4014,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4017,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4017,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4019,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4020:11) and DISPLS(i) (4020:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4019,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4028,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4028,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4028,10)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4028,10)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4037,13)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4032,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4032,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4032,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4014,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4032,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(3936,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_put_var_real8_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:3936

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1015
            Global    :     122
            Local     :     893
        Regenerable   :     217
        Spilled       :      14
        
    Routine stack
        Variables     :     780 bytes*
            Reads     :      62 [3.88e+00 ~ 3.9%]
            Writes    :     178 [9.93e+00 ~ 9.9%]
        Spills        :      72 bytes*
            Reads     :      11 [1.08e+00 ~ 1.1%]
            Writes    :      12 [5.64e-01 ~ 0.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL8_2D) [45] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4051,12)
  -> INLINE: (4077,19) CISM_PARALLEL::GET_BOUNDS_INFO
    -> INLINE: (4999,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4088,10) CISM_PARALLEL::FC_GATHER_INT
  -> (4113,10) CISM_PARALLEL::FC_GATHERV_REAL8
  -> INLINE: (4124,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4096,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4096,8)
      remark #25408: memset generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4096,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4096,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4099,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4099,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4101,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4102:11) and DISPLS(i) (4102:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4101,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4111,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4111,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4111,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4111,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4111,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4111,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4121,39)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4096,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4117,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4051,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_put_var_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4051

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1027
            Global    :     166
            Local     :     861
        Regenerable   :     134
        Spilled       :      41
        
    Routine stack
        Variables     :     788 bytes*
            Reads     :      61 [1.31e+00 ~ 1.3%]
            Writes    :     185 [4.61e+00 ~ 4.6%]
        Spills        :     288 bytes*
            Reads     :      57 [4.39e+00 ~ 4.4%]
            Writes    :      44 [1.50e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_PUT_VAR_REAL8_3D) [46] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4132,12)
  -> INLINE: (4160,19) CISM_PARALLEL::GET_BOUNDS_INFO
    -> INLINE: (4999,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4171,10) CISM_PARALLEL::FC_GATHER_INT
  -> (4198,10) CISM_PARALLEL::FC_GATHERV_REAL8
  -> INLINE: (4209,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4179,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4179,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4179,8)
         remark #25408: memset generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4179,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4179,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4182,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4182,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4185,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4186:11) and DISPLS(i) (4186:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4185,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4195,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4195,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4195,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4195,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
            remark #25399: memcopy generated
            remark #15542: loop was not vectorized: inner loop was already vectorized

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
               remark #15300: LOOP WAS VECTORIZED
            LOOP END

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11)
            <Remainder loop for vectorization>
            LOOP END
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4179,8):remark #34026: call to memset implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4202,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4132,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_put_var_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4132

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1082
            Global    :     185
            Local     :     897
        Regenerable   :     134
        Spilled       :      76
        
    Routine stack
        Variables     :     860 bytes*
            Reads     :      70 [4.88e-01 ~ 0.5%]
            Writes    :     200 [1.28e+00 ~ 1.3%]
        Spills        :     568 bytes*
            Reads     :     114 [6.63e+00 ~ 6.6%]
            Writes    :      94 [2.80e+00 ~ 2.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_INTEGER_2D) [47] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4220,14)
  -> INLINE: (4250,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4268,10) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4275,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4275,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4278,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4279:11) and DISPLS(i) (4279:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4278,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4283,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4298,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4298,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4298,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4298,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4298,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4298,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4284,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4220,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_scatter_var_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4220

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     901
            Global    :     141
            Local     :     760
        Regenerable   :     125
        Spilled       :      43
        
    Routine stack
        Variables     :     580 bytes*
            Reads     :      40 [1.23e+00 ~ 1.2%]
            Writes    :     118 [3.65e+00 ~ 3.7%]
        Spills        :     296 bytes*
            Reads     :      60 [5.62e+00 ~ 5.6%]
            Writes    :      46 [1.92e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_LOGICAL_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_LOGICAL_2D) [48] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4307,14)
  -> INLINE: (4337,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4355,10) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4361,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4361,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4364,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4365:11) and DISPLS(i) (4365:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4364,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4369,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4384,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4384,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4384,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4384,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4384,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4384,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4370,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4307,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_scatter_var_logical_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4307

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     902
            Global    :     140
            Local     :     762
        Regenerable   :     126
        Spilled       :      43
        
    Routine stack
        Variables     :     580 bytes*
            Reads     :      40 [1.23e+00 ~ 1.2%]
            Writes    :     118 [3.65e+00 ~ 3.7%]
        Spills        :     296 bytes*
            Reads     :      60 [5.62e+00 ~ 5.6%]
            Writes    :      46 [1.92e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_REAL4_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_REAL4_2D) [49] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4393,14)
  -> INLINE: (4423,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4441,10) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4447,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4447,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4450,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4451:11) and DISPLS(i) (4451:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4450,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4455,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4470,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4470,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4470,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4470,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4470,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4470,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4456,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4393,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_scatter_var_real4_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4393

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     902
            Global    :     140
            Local     :     762
        Regenerable   :     126
        Spilled       :      43
        
    Routine stack
        Variables     :     580 bytes*
            Reads     :      40 [1.23e+00 ~ 1.2%]
            Writes    :     118 [3.65e+00 ~ 3.7%]
        Spills        :     296 bytes*
            Reads     :      60 [5.62e+00 ~ 5.6%]
            Writes    :      46 [1.92e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_REAL4_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_REAL4_3D) [50] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4479,14)
  -> INLINE: (4509,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4527,10) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4533,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4533,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4536,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4537:11) and DISPLS(i) (4537:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4536,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4541,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11)
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11)
            remark #25399: memcopy generated
            remark #15542: loop was not vectorized: inner loop was already vectorized

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11)
               remark #15300: LOOP WAS VECTORIZED
            LOOP END

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11)
            <Remainder loop for vectorization>
            LOOP END
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4558,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4558,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4558,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4558,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4558,5)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4558,5)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4558,5)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4542,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4479,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_scatter_var_real4_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4479

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     929
            Global    :     151
            Local     :     778
        Regenerable   :     126
        Spilled       :      63
        
    Routine stack
        Variables     :     604 bytes*
            Reads     :      40 [3.27e-01 ~ 0.3%]
            Writes    :     124 [1.18e+00 ~ 1.2%]
        Spills        :     448 bytes*
            Reads     :      94 [6.85e+00 ~ 6.9%]
            Writes    :      68 [2.50e+00 ~ 2.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_REAL8_2D) [51] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4567,14)
  -> INLINE: (4597,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4615,10) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4621,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4621,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4624,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4625:11) and DISPLS(i) (4625:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4624,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4629,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4644,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4644,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4644,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4644,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4644,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4644,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4630,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4567,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_scatter_var_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4567

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     879
            Global    :     126
            Local     :     753
        Regenerable   :     127
        Spilled       :      33
        
    Routine stack
        Variables     :     580 bytes*
            Reads     :      38 [1.10e+00 ~ 1.1%]
            Writes    :     118 [3.53e+00 ~ 3.5%]
        Spills        :     208 bytes*
            Reads     :      47 [4.60e+00 ~ 4.6%]
            Writes    :      35 [1.45e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_REAL8_3D) [52] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4653,14)
  -> INLINE: (4685,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4709,10) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4715,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4715,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4719,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4720:11) and DISPLS(i) (4720:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4719,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4724,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11)
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11)
            remark #25399: memcopy generated
            remark #15542: loop was not vectorized: inner loop was already vectorized

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11)
               remark #15300: LOOP WAS VECTORIZED
            LOOP END

            LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11)
            <Remainder loop for vectorization>
            LOOP END
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4741,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4741,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4741,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4741,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4741,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4741,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4741,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4725,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4653,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_scatter_var_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4653

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     921
            Global    :     145
            Local     :     776
        Regenerable   :     127
        Spilled       :      59
        
    Routine stack
        Variables     :     604 bytes*
            Reads     :      40 [3.08e-01 ~ 0.3%]
            Writes    :     124 [1.11e+00 ~ 1.1%]
        Spills        :     416 bytes*
            Reads     :      93 [5.62e+00 ~ 5.6%]
            Writes    :      67 [2.49e+00 ~ 2.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_ROW_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_ROW_REAL8_2D) [53] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4753,14)
  -> INLINE: (4791,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4808,13) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4815,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4815,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4818,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4819:11) and DISPLS(i) (4819:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4818,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4842,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4823,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4753,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_scatter_var_row_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4753

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     786
            Global    :     137
            Local     :     649
        Regenerable   :     117
        Spilled       :      45
        
    Routine stack
        Variables     :     556 bytes*
            Reads     :      30 [7.22e-01 ~ 0.7%]
            Writes    :     104 [3.15e+00 ~ 3.1%]
        Spills        :     312 bytes*
            Reads     :      82 [5.21e+00 ~ 5.2%]
            Writes    :      58 [1.95e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_COL_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::DISTRIBUTED_SCATTER_VAR_COL_REAL8_2D) [54] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4853,14)
  -> INLINE: (4890,13) CISM_PARALLEL::PARALLEL_STOP
  -> (4907,13) CISM_PARALLEL::FC_GATHER_INT


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4914,8)
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 4  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4914,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4917,8)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
   remark #15346: vector dependence: assumed FLOW dependence between DISPLS(i+1) (4918:11) and DISPLS(i) (4918:11)
   remark #25439: unrolled with remainder by 2  
   remark #25456: Number of Array Refs Scalar Replaced In Loop: 2
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4917,8)
<Remainder>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11)
         remark #25399: memcopy generated
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11)
      remark #25399: memcopy generated
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4941,10)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4922,11):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4853,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_distributed_scatter_var_col_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4853

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     786
            Global    :     137
            Local     :     649
        Regenerable   :     117
        Spilled       :      45
        
    Routine stack
        Variables     :     556 bytes*
            Reads     :      30 [7.22e-01 ~ 0.7%]
            Writes    :     104 [3.15e+00 ~ 3.1%]
        Spills        :     312 bytes*
            Reads     :      82 [5.21e+00 ~ 5.2%]
            Writes    :      58 [1.95e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::GET_BOUNDS_INFO

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::GET_BOUNDS_INFO) [55] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4950,12)
  -> INLINE: (4999,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(4950,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_get_bounds_info_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:4950

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   10[ rax rdx rcx rbx rsi rdi r8-r11]
        
    Routine temporaries
        Total         :      93
            Global    :      12
            Local     :      81
        Regenerable   :      39
        Spilled       :       1
        
    Routine stack
        Variables     :     124 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       8 [1.53e-01 ~ 0.2%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::NOT_PARALLEL

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::NOT_PARALLEL) [56] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5008,14)
  -> INLINE: (5015,10) CISM_PARALLEL::PARALLEL_STOP


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5008,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_not_parallel_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5008

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   10[ rax rdx rcx rsi rdi r8-r9 r13-r15]
        
    Routine temporaries
        Total         :      52
            Global    :      11
            Local     :      41
        Regenerable   :      39
        Spilled       :       3
        
    Routine stack
        Variables     :     124 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       8 [6.78e+00 ~ 6.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_BOUNDARY

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_BOUNDARY) [57] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5035,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5035,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_boundary_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5035

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rsi rdi r8-r11]
        
    Routine temporaries
        Total         :      48
            Global    :       0
            Local     :      48
        Regenerable   :       1
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_BOUNDARY_VALUE_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_BOUNDARY_VALUE_REAL8_2D) [58] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5067,14)
  -> INLINE: (5089,15) CISM_PARALLEL::PARALLEL_BOUNDARY


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5087,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5088,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5088,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5067,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_boundary_value_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5067

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   30[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm15]
        
    Routine temporaries
        Total         :     128
            Global    :      55
            Local     :      73
        Regenerable   :       7
        Spilled       :      24
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :     168 bytes*
            Reads     :      38 [9.65e+00 ~ 9.7%]
            Writes    :      28 [2.66e+00 ~ 2.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_BOUNDARY_VALUE_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_BOUNDARY_VALUE_REAL8_3D) [59] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5100,14)
  -> INLINE: (5122,15) CISM_PARALLEL::PARALLEL_BOUNDARY


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5120,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5121,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5123,14)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5123,14)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5100,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_boundary_value_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5100

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   16[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm1]
        
    Routine temporaries
        Total         :      97
            Global    :      52
            Local     :      45
        Regenerable   :       2
        Spilled       :      35
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      36 [1.29e+01 ~ 12.9%]
            Writes    :      28 [3.06e+00 ~ 3.1%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_CLOSE

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_CLOSE) [60] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5134,12)
  -> INLINE: (5143,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5134,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_close_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5134

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      27
            Global    :       9
            Local     :      18
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [4.11e+00 ~ 4.1%]
            Writes    :       2 [4.76e+00 ~ 4.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_CONVERT_HALOED_TO_NONHALOED_REAL4_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_CONVERT_HALOED_TO_NONHALOED_REAL4_2D) [61] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5151,14)
  -> INLINE: (5169,13) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (5176,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5179,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5179,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5179,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5179,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5179,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5179,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5151,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_convert_haloed_to_nonhaloed_real4_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5151

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     238
            Global    :      56
            Local     :     182
        Regenerable   :     153
        Spilled       :      17
        
    Routine stack
        Variables     :     440 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      36 [4.12e+00 ~ 4.1%]
        Spills        :      96 bytes*
            Reads     :      16 [5.72e+00 ~ 5.7%]
            Writes    :      12 [1.92e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_CONVERT_HALOED_TO_NONHALOED_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_CONVERT_HALOED_TO_NONHALOED_REAL8_2D) [62] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5187,14)
  -> INLINE: (5205,13) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (5212,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5215,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5215,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5215,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5215,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5215,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5215,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5187,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_convert_haloed_to_nonhaloed_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5187

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     238
            Global    :      56
            Local     :     182
        Regenerable   :     153
        Spilled       :      18
        
    Routine stack
        Variables     :     440 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      36 [4.12e+00 ~ 4.1%]
        Spills        :     104 bytes*
            Reads     :      15 [5.63e+00 ~ 5.6%]
            Writes    :      13 [1.92e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_CONVERT_NONHALOED_TO_HALOED_REAL4_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_CONVERT_NONHALOED_TO_HALOED_REAL4_2D) [63] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5226,14)
  -> INLINE: (5244,13) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (5251,13) CISM_PARALLEL::PARALLEL_STOP
  -> (5257,10) CISM_PARALLEL::PARALLEL_HALO_REAL4_2D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5254,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5254,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5254,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5254,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5254,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5254,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5226,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_convert_nonhaloed_to_haloed_real4_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5226

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     251
            Global    :      63
            Local     :     188
        Regenerable   :     153
        Spilled       :      19
        
    Routine stack
        Variables     :     440 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      36 [3.99e+00 ~ 4.0%]
        Spills        :     112 bytes*
            Reads     :      20 [5.90e+00 ~ 5.9%]
            Writes    :      16 [2.22e+00 ~ 2.2%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_REAL4_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_REAL4_2D) [64] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6264,14)
  -> (6300,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6313,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6313,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6313,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6313,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6313,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6313,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6316,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6316,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6316,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6316,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6316,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6316,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6320,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6320,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6320,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6320,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6320,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6320,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6322,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6322,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6322,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6322,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6322,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6322,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6324,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6324,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6324,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6324,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6324,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6324,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6326,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6326,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6326,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6326,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6326,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6326,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6330,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6330,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6330,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6330,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6330,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6330,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6332,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6332,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6332,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6332,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6332,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6332,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6338,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6338,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6338,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6338,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6338,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6338,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6342,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6342,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6342,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6342,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6342,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6342,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6346,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6346,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6346,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6346,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6346,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6346,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6350,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6350,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6350,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6350,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6350,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6350,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6359,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6359,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6359,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6359,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6359,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6359,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6363,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6363,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6363,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6363,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6363,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6363,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6367,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6367,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6367,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6367,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6367,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6367,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6371,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6371,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6371,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6371,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6371,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6371,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6376,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6376,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6376,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6376,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6376,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6376,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6377,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6377,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6377,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6377,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6377,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6377,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6378,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6378,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6378,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6378,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6378,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6378,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6379,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6379,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6379,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6379,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6379,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6379,30)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6264,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_real4_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6264

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     914
            Global    :     530
            Local     :     384
        Regenerable   :     142
        Spilled       :     110
        
    Routine stack
        Variables     :     212 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      21 [5.45e-01 ~ 0.5%]
        Spills        :     792 bytes*
            Reads     :     278 [5.07e+00 ~ 5.1%]
            Writes    :     220 [2.63e+00 ~ 2.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_CONVERT_NONHALOED_TO_HALOED_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_CONVERT_NONHALOED_TO_HALOED_REAL8_2D) [65] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5264,14)
  -> INLINE: (5282,13) CISM_PARALLEL::PARALLEL_STOP
  -> INLINE: (5289,13) CISM_PARALLEL::PARALLEL_STOP
  -> (5295,10) CISM_PARALLEL::PARALLEL_HALO_REAL8_2D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5292,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5292,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5292,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5292,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5292,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5292,5)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5264,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_convert_nonhaloed_to_haloed_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5264

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     253
            Global    :      63
            Local     :     190
        Regenerable   :     155
        Spilled       :      19
        
    Routine stack
        Variables     :     440 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      36 [3.97e+00 ~ 4.0%]
        Spills        :     112 bytes*
            Reads     :      20 [5.87e+00 ~ 5.9%]
            Writes    :      16 [2.22e+00 ~ 2.2%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_REAL8_2D) [66] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6388,14)
  -> (6431,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6444,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6444,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6444,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6444,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6444,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6444,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6447,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6447,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6447,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6447,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6447,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6447,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6450,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6450,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6450,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6450,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6450,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6450,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6452,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6452,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6452,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6452,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6452,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6452,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6458,14)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6458,14)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6458,14)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6458,14)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6458,14)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6458,14)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6463,14)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6463,14)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6463,14)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6463,14)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6463,14)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6463,14)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6469,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6469,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6469,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6469,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6469,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6469,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6471,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6471,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6471,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6471,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6471,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6471,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6475,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6475,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6475,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6475,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6475,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6475,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6477,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6477,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6477,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6477,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6477,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6477,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6483,14)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6483,14)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6483,14)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6483,14)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6483,14)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6483,14)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6487,14)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6487,14)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6487,14)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6487,14)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6487,14)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6487,14)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6496,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6496,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6496,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6496,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6496,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6496,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6500,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6500,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6500,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6500,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6500,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6500,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6504,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6504,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6504,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6504,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6504,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6504,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6508,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6508,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6508,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6508,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6508,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6508,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6517,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6517,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6517,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6517,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6517,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6517,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6521,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6521,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6521,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6521,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6521,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6521,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6525,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6525,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6525,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6525,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6525,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6525,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6529,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6529,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6529,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6529,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6529,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6529,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6534,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6534,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6534,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6534,30)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6534,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6534,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6535,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6535,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6535,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6535,30)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6535,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6535,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6536,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6536,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6536,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6536,30)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6536,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6536,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6537,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6537,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6537,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6537,30)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6537,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6537,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6388,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6388

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   20[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm5]
        
    Routine temporaries
        Total         :    1236
            Global    :     629
            Local     :     607
        Regenerable   :     131
        Spilled       :     173
        
    Routine stack
        Variables     :     212 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      21 [3.47e-01 ~ 0.3%]
        Spills        :    1272 bytes*
            Reads     :     411 [2.58e+00 ~ 2.6%]
            Writes    :     336 [1.78e+00 ~ 1.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_CREATE

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_CREATE) [67] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5303,12)
  -> INLINE: (5312,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5313,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5303,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_create_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5303

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      49
            Global    :      15
            Local     :      34
        Regenerable   :      25
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.19e+00 ~ 2.2%]
            Writes    :       3 [5.26e+00 ~ 5.3%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_CREATE_COMM_ROW

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_CREATE_COMM_ROW) [68] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5323,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5323,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_create_comm_row_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5323

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   10[ rax rdx rcx rbx rsi rdi r8 r12 r14-r15]
        
    Routine temporaries
        Total         :      62
            Global    :      13
            Local     :      49
        Regenerable   :      37
        Spilled       :       4
        
    Routine stack
        Variables     :     116 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       7 [4.90e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_CREATE_COMM_COL

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_CREATE_COMM_COL) [69] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5360,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5360,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_create_comm_col_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5360

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   10[ rax rdx rcx rbx rsi rdi r8 r12 r14-r15]
        
    Routine temporaries
        Total         :      62
            Global    :      13
            Local     :      49
        Regenerable   :      37
        Spilled       :       4
        
    Routine stack
        Variables     :     116 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       7 [4.90e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_DEF_DIM

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_DEF_DIM) [70] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5397,12)
  -> INLINE: (5408,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5409,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5397,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_def_dim_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5397

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      49
            Global    :      16
            Local     :      33
        Regenerable   :      21
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.37e+00 ~ 2.4%]
            Writes    :       3 [5.69e+00 ~ 5.7%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_DEF_VAR_DIMIDS

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_DEF_VAR_DIMIDS) [71] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5417,12)
  -> INLINE: (5427,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5428,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5417,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_def_var_dimids_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5417

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      53
            Global    :      17
            Local     :      36
        Regenerable   :      23
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.03e+00 ~ 2.0%]
            Writes    :       3 [4.88e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_DEF_VAR_NODIMIDS

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_DEF_VAR_NODIMIDS) [72] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5433,12)
  -> INLINE: (5442,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5443,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5433,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_def_var_nodimids_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5433

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      49
            Global    :      16
            Local     :      33
        Regenerable   :      21
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.37e+00 ~ 2.4%]
            Writes    :       3 [5.69e+00 ~ 5.7%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_ENDDEF

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_ENDDEF) [73] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5449,12)
  -> INLINE: (5456,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5449,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_enddef_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5449

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      31
            Global    :       9
            Local     :      22
        Regenerable   :      17
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [4.01e+00 ~ 4.0%]
            Writes    :       2 [4.64e+00 ~ 4.6%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_FINALISE

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_FINALISE) [74] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5462,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5462,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_finalise_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5462

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    1[ rdi]
        
    Routine temporaries
        Total         :       8
            Global    :       6
            Local     :       2
        Regenerable   :       2
        Spilled       :       0
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_ATT_CHARACTER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_ATT_CHARACTER) [75] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5477,12)
  -> INLINE: (5486,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5487,10) CISM_PARALLEL::BROADCAST_CHARACTER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5477,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_att_character_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5477

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   10[ rax rdx rcx rbx rsi rdi r8-r10 r15]
        
    Routine temporaries
        Total         :      54
            Global    :      15
            Local     :      39
        Regenerable   :      23
        Spilled       :       2
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       1 [1.98e+00 ~ 2.0%]
            Writes    :       4 [6.72e+00 ~ 6.7%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_ATT_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_ATT_REAL4) [76] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5492,12)
  -> INLINE: (5502,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5503,10) CISM_PARALLEL::BROADCAST_REAL4


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5492,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_att_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5492

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      51
            Global    :      14
            Local     :      37
        Regenerable   :      23
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.37e+00 ~ 2.4%]
            Writes    :       3 [5.69e+00 ~ 5.7%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_ATT_REAL4_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_ATT_REAL4_1D) [77] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5508,12)
  -> INLINE: (5518,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5519,10) CISM_PARALLEL::BROADCAST_REAL4_1D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5519,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5519,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5519,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5519,10)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5519,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5519,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5519,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5519,10)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5508,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_att_real4_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5508

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     102
            Global    :      43
            Local     :      59
        Regenerable   :      24
        Spilled       :       6
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       1 [8.02e-01 ~ 0.8%]
            Writes    :       4 [2.73e+00 ~ 2.7%]
        Spills        :       8 bytes*
            Reads     :       1 [8.02e-01 ~ 0.8%]
            Writes    :       1 [8.02e-01 ~ 0.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_ATT_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_ATT_REAL8) [78] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5524,12)
  -> INLINE: (5534,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5535,10) CISM_PARALLEL::BROADCAST_REAL8


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5524,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_att_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5524

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      51
            Global    :      14
            Local     :      37
        Regenerable   :      23
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.37e+00 ~ 2.4%]
            Writes    :       3 [5.69e+00 ~ 5.7%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_ATT_REAL8_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_ATT_REAL8_1D) [79] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5540,12)
  -> INLINE: (5550,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5551,10) CISM_PARALLEL::BROADCAST_REAL8_1D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5551,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5551,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5551,10)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5551,10)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5551,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5551,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5551,10)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5551,10)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5540,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_att_real8_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5540

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      93
            Global    :      37
            Local     :      56
        Regenerable   :      24
        Spilled       :       6
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       1 [6.69e-01 ~ 0.7%]
            Writes    :       4 [2.27e+00 ~ 2.3%]
        Spills        :       8 bytes*
            Reads     :       7 [1.24e+00 ~ 1.2%]
            Writes    :       1 [2.01e-01 ~ 0.2%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_VAR_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_VAR_INTEGER) [80] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5564,12)
  -> INLINE: (5572,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5573,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5564,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_var_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5564

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      44
            Global    :      14
            Local     :      30
        Regenerable   :      22
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.52e+00 ~ 2.5%]
            Writes    :       3 [5.45e+00 ~ 5.4%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_VAR_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_VAR_REAL4) [81] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5578,12)
  -> INLINE: (5586,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5587,10) CISM_PARALLEL::BROADCAST_REAL4


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5578,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_var_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5578

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      46
            Global    :      12
            Local     :      34
        Regenerable   :      24
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.52e+00 ~ 2.5%]
            Writes    :       3 [5.45e+00 ~ 5.4%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_VAR_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_VAR_REAL8) [82] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5592,12)
  -> INLINE: (5600,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5601,10) CISM_PARALLEL::BROADCAST_REAL8


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5592,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_var_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5592

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      46
            Global    :      12
            Local     :      34
        Regenerable   :      24
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.52e+00 ~ 2.5%]
            Writes    :       3 [5.45e+00 ~ 5.4%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_VAR_INTEGER_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_VAR_INTEGER_1D) [83] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5606,12)
  -> INLINE: (5615,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5616,10) CISM_PARALLEL::BROADCAST_INTEGER_1D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5616,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5616,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5616,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5616,10)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5616,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5616,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5616,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5616,10)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5606,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_var_integer_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5606

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      99
            Global    :      41
            Local     :      58
        Regenerable   :      27
        Spilled       :       6
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       1 [8.13e-01 ~ 0.8%]
            Writes    :       4 [2.57e+00 ~ 2.6%]
        Spills        :       8 bytes*
            Reads     :       1 [8.13e-01 ~ 0.8%]
            Writes    :       1 [8.13e-01 ~ 0.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_VAR_REAL4_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_VAR_REAL4_1D) [84] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5620,12)
  -> INLINE: (5629,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5630,10) CISM_PARALLEL::BROADCAST_REAL4_1D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5630,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5630,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5630,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5630,10)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5630,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5630,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5630,10)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(539,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5630,10)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5620,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_var_real4_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5620

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      99
            Global    :      41
            Local     :      58
        Regenerable   :      27
        Spilled       :       6
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       1 [8.13e-01 ~ 0.8%]
            Writes    :       4 [2.57e+00 ~ 2.6%]
        Spills        :       8 bytes*
            Reads     :       1 [8.13e-01 ~ 0.8%]
            Writes    :       1 [8.13e-01 ~ 0.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_VAR_REAL8_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_VAR_REAL8_1D) [85] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5634,12)
  -> INLINE: (5643,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5644,10) CISM_PARALLEL::BROADCAST_REAL8_1D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5644,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5644,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5644,10)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5644,10)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5644,10)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5644,10)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5644,10)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(581,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5644,10)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5634,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_var_real8_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5634

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      90
            Global    :      35
            Local     :      55
        Regenerable   :      27
        Spilled       :       6
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       1 [6.77e-01 ~ 0.7%]
            Writes    :       4 [2.14e+00 ~ 2.1%]
        Spills        :       8 bytes*
            Reads     :       7 [1.25e+00 ~ 1.3%]
            Writes    :       1 [2.03e-01 ~ 0.2%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_VAR_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_VAR_INTEGER_2D) [86] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5649,12)
  -> INLINE: (5658,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5649,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_var_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5649

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      36
            Global    :      11
            Local     :      25
        Regenerable   :      16
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.67e+00 ~ 3.7%]
            Writes    :       2 [4.25e+00 ~ 4.2%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GET_VAR_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GET_VAR_REAL8_2D) [87] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5664,12)
  -> INLINE: (5673,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5664,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_get_var_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5664

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      36
            Global    :      11
            Local     :      25
        Regenerable   :      16
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.67e+00 ~ 3.7%]
            Writes    :       2 [4.25e+00 ~ 4.2%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GLOBAL_EDGE_MASK

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GLOBAL_EDGE_MASK) [88] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5680,14)
  -> INLINE: (5702,13) CISM_PARALLEL::PARALLEL_STOP
  -> (5725,10) CISM_PARALLEL::PARALLEL_HALO_INTEGER_2D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5707,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5707,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5707,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5707,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5707,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5707,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5710,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5710,8)
<Remainder, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5710,8)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5710,8)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5714,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5714,8)
<Remainder, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5714,8)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5714,8)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5718,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5718,8)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5718,8)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5718,8)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5722,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5722,8)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5722,8)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5722,8)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5680,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_global_edge_mask_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5680

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     284
            Global    :     107
            Local     :     177
        Regenerable   :      94
        Spilled       :      18
        
    Routine stack
        Variables     :     284 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      21 [2.70e+00 ~ 2.7%]
        Spills        :      56 bytes*
            Reads     :      12 [8.17e-01 ~ 0.8%]
            Writes    :      12 [8.22e-01 ~ 0.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_INTEGER_2D) [89] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6015,14)
  -> (6052,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6065,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6065,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6065,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6065,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6065,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6065,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6068,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6068,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6068,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6068,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6068,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6068,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6072,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6072,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6072,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6072,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6072,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6072,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6074,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6074,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6074,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6074,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6074,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6074,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6076,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6076,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6076,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6076,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6076,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6076,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6078,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6078,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6078,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6078,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6078,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6078,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6082,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6082,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6082,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6082,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6082,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6082,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6084,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6084,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6084,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6084,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6084,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6084,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6090,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6090,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6090,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6090,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6090,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6090,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6094,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6094,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6094,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6094,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6094,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6094,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6098,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6098,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6098,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6098,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6098,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6098,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6102,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6102,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6102,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6102,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6102,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6102,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6111,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6111,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6111,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6111,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6111,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6111,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6115,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6115,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6115,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6115,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6115,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6115,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6119,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6119,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6119,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6119,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6119,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6119,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6123,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6123,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6123,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6123,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6123,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6123,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6128,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6128,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6128,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6128,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6128,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6128,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6129,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6129,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6129,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6129,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6129,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6129,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6130,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6130,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6130,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6130,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6130,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6130,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6131,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6131,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6131,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6131,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6131,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6131,30)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6015,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6015

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     904
            Global    :     520
            Local     :     384
        Regenerable   :     141
        Spilled       :     111
        
    Routine stack
        Variables     :     212 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      21 [5.52e-01 ~ 0.6%]
        Spills        :     768 bytes*
            Reads     :     260 [5.08e+00 ~ 5.1%]
            Writes    :     204 [2.60e+00 ~ 2.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GLOBALID

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GLOBALID) [90] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5735,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5735,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_globalid_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5735

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rsi rdi r8-r11]
        
    Routine temporaries
        Total         :      42
            Global    :      13
            Local     :      29
        Regenerable   :       0
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GLOBALID_SCALAR

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GLOBALID_SCALAR) [91] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5812,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5812,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_globalid_scalar_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5812

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rsi rdi r8-r11]
        
    Routine temporaries
        Total         :      28
            Global    :       0
            Local     :      28
        Regenerable   :       0
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GLOBALINDEX

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GLOBALINDEX) [92] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5855,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5855,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_globalindex_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5855

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    8[ rax rdx rcx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      23
            Global    :       0
            Local     :      23
        Regenerable   :       0
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GLOBAL_SUM_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GLOBAL_SUM_INTEGER_2D) [93] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5880,12)
  -> INLINE: (5901,38) CISM_PARALLEL::PARALLEL_REDUCE_SUM_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5896,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5897,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5897,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5896,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5897,8)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5897,8)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5880,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_global_sum_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5880

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   17[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm2]
        
    Routine temporaries
        Total         :      96
            Global    :      41
            Local     :      55
        Regenerable   :      16
        Spilled       :      10
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [2.96e-01 ~ 0.3%]
            Writes    :       1 [2.96e-01 ~ 0.3%]
        Spills        :      40 bytes*
            Reads     :       5 [3.48e+00 ~ 3.5%]
            Writes    :       5 [1.20e+00 ~ 1.2%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GLOBAL_SUM_REAL4_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GLOBAL_SUM_REAL4_2D) [94] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5909,12)
  -> INLINE: (5930,36) CISM_PARALLEL::PARALLEL_REDUCE_SUM_REAL4


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5925,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5926,8)
      remark #15331: loop was not vectorized: precise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model   [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5927,11) ]
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5926,8)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5925,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5926,8)
      remark #15331: loop was not vectorized: precise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model   [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5927,11) ]
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5926,8)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5909,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_global_sum_real4_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5909

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      88
            Global    :      39
            Local     :      49
        Regenerable   :      16
        Spilled       :       9
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [4.08e-01 ~ 0.4%]
            Writes    :       1 [4.08e-01 ~ 0.4%]
        Spills        :      32 bytes*
            Reads     :       4 [3.78e+00 ~ 3.8%]
            Writes    :       4 [1.47e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_GLOBAL_SUM_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_GLOBAL_SUM_REAL8_2D) [95] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5938,12)
  -> INLINE: (5959,36) CISM_PARALLEL::PARALLEL_REDUCE_SUM_REAL8


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5954,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5955,8)
      remark #15331: loop was not vectorized: precise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model   [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5956,11) ]
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5955,8)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5954,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5955,8)
      remark #15331: loop was not vectorized: precise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model   [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5956,11) ]
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5955,8)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5938,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_global_sum_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5938

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      89
            Global    :      40
            Local     :      49
        Regenerable   :      16
        Spilled       :       9
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [3.94e-01 ~ 0.4%]
            Writes    :       1 [3.94e-01 ~ 0.4%]
        Spills        :      32 bytes*
            Reads     :       4 [3.65e+00 ~ 3.6%]
            Writes    :       4 [1.42e+00 ~ 1.4%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_LOCALINDEX

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_LOCALINDEX) [96] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5967,14)
  -> INLINE: (5995,10) CISM_PARALLEL::PARALLEL_REDUCE_MAXLOC_INTEGER
  -> INLINE: (5998,13) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (5999,13) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (6003,16) CISM_PARALLEL::PARALLEL_STOP


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(5967,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_localindex_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:5967

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   14[ rax rdx rcx rbx rsi rdi r8-r15]
        
    Routine temporaries
        Total         :     126
            Global    :      24
            Local     :     102
        Regenerable   :      91
        Spilled       :       5
        
    Routine stack
        Variables     :     240 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      15 [4.57e-01 ~ 0.5%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_LOGICAL_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_LOGICAL_2D) [97] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6140,14)
  -> (6176,13) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6189,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6189,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6189,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6189,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6189,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6189,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6192,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6192,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6192,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6192,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6192,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6192,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6196,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6196,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6196,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6196,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6196,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6196,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6198,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6198,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6198,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6198,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6198,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6198,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6200,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6200,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6200,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6200,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6200,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6200,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6202,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6202,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6202,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6202,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6202,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6202,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6206,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6206,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6206,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6206,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6206,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6206,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6208,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6208,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6208,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6208,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6208,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6208,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6214,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6214,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6214,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6214,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6214,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6214,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6218,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6218,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6218,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6218,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6218,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6218,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6222,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6222,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6222,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6222,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6222,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6222,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6226,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6226,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6226,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6226,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6226,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6226,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6235,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6235,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6235,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6235,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6235,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6235,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6239,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6239,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6239,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6239,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6239,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6239,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6243,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6243,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6243,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6243,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6243,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6243,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6247,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6247,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6247,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6247,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6247,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6247,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6252,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6252,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6252,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6252,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6252,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6252,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6253,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6253,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6253,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6253,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6253,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6253,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6254,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6254,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6254,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6254,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6254,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6254,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6255,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6255,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6255,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6255,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6255,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6255,30)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6140,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_logical_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6140

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     904
            Global    :     520
            Local     :     384
        Regenerable   :     141
        Spilled       :     111
        
    Routine stack
        Variables     :     212 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      21 [5.52e-01 ~ 0.6%]
        Spills        :     768 bytes*
            Reads     :     260 [5.08e+00 ~ 5.1%]
            Writes    :     204 [2.60e+00 ~ 2.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_REAL8_3D) [98] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6546,14)
  -> (6582,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6595,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6595,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6595,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6595,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6595,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6595,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6595,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6598,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6598,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6598,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6598,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6598,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6598,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6598,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6602,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6602,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6602,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6602,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6602,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6602,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6602,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6604,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6604,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6604,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6604,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6604,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6604,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6604,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6606,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6606,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6606,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6606,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6606,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6606,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6606,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6608,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6608,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6608,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6608,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6608,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6608,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6608,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6612,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6612,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6612,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6612,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6612,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6612,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6612,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6614,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6614,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6614,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6614,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6614,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6614,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6614,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6620,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6620,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6620,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6620,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6620,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6620,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6620,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6624,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6624,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6624,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6624,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6624,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6624,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6624,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6628,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6628,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6628,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6628,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6628,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6628,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6628,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6632,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6632,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6632,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6632,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6632,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6632,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6632,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6641,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6641,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6641,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6641,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6641,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6641,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6641,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6645,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6645,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6645,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6645,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6645,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6645,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6645,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6649,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6649,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6649,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6649,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6649,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6649,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6649,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6653,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6653,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6653,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6653,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6653,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6653,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6653,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6658,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6658,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6658,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6658,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6658,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6658,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6658,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6659,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6659,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6659,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6659,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6659,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6659,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6659,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6660,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6660,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6660,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6660,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6660,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6660,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6660,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6661,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6661,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6661,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6661,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6661,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6661,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6661,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6546,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6546

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1197
            Global    :     667
            Local     :     530
        Regenerable   :     139
        Spilled       :     326
        
    Routine stack
        Variables     :     236 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      24 [9.69e-02 ~ 0.1%]
        Spills        :    2504 bytes*
            Reads     :     751 [3.27e+00 ~ 3.3%]
            Writes    :     507 [1.29e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_REAL8_4D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_REAL8_4D) [99] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6670,14)
  -> (6706,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6719,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6719,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6719,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6719,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6719,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6719,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6719,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6719,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6722,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6722,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6722,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6722,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6722,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6722,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6722,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6722,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6726,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6726,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6726,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6726,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6726,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6726,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6726,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6726,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6728,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6728,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6728,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6728,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6728,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6728,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6728,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6728,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6730,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6730,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6730,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6730,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6730,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6730,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6730,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6730,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6732,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6732,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6732,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6732,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6732,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6732,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6732,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6732,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6736,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6736,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6736,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6736,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6736,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6736,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6736,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6736,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6738,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6738,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6738,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6738,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6738,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6738,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6738,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6738,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6744,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6744,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6744,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6744,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6744,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6744,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6744,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6744,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6748,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6748,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6748,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6748,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6748,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6748,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6748,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6748,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6752,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6752,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6752,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6752,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6752,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6752,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6752,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6752,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6756,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6756,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6756,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6756,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6756,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6756,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6756,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6756,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6765,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6765,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6765,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6765,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6765,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6765,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6765,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6765,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6769,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6769,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6769,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6769,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6769,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6769,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6769,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6769,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6773,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6773,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6773,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6773,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6773,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6773,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6773,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6773,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6777,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6777,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6777,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6777,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6777,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6777,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6777,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6777,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6782,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6782,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6782,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6782,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6782,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6782,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6782,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6782,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6783,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6783,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6783,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6783,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6783,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6783,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6783,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6783,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6784,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6784,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6784,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6784,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6784,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6784,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6784,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6784,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6785,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6785,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6785,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6785,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6785,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6785,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6785,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6785,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6670,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_real8_4d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6670

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1514
            Global    :     744
            Local     :     770
        Regenerable   :     148
        Spilled       :     421
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      27 [2.18e-02 ~ 0.0%]
        Spills        :    3248 bytes*
            Reads     :     856 [3.11e+00 ~ 3.1%]
            Writes    :     576 [1.51e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_VERIFY_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_VERIFY_INTEGER_2D) [100] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7186,12)
  -> INLINE: (7219,10) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7231,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7231,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7231,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7231,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7231,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7231,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7234,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7234,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7234,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7234,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7234,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7234,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7239,22)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7239,22)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7239,22)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7242,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7242,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7242,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7244,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7244,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7244,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7244,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7244,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7244,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7246,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7246,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7246,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7246,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7246,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7246,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7250,42)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7250,42)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7250,42)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7252,42)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7252,42)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7252,42)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7186,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_verify_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7186

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   21[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm6]
        
    Routine temporaries
        Total         :     582
            Global    :     230
            Local     :     352
        Regenerable   :     125
        Spilled       :      60
        
    Routine stack
        Variables     :     264 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      20 [1.99e-01 ~ 0.2%]
        Spills        :     424 bytes*
            Reads     :     125 [4.08e+00 ~ 4.1%]
            Writes    :      84 [1.62e+00 ~ 1.6%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_VERIFY_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_VERIFY_REAL8_2D) [101] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7267,12)
  -> INLINE: (7299,10) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7311,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7311,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7311,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7311,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7311,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7311,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7314,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7314,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7314,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7314,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7314,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7314,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7318,22)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7318,22)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7318,22)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7318,22)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7321,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7321,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7321,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7321,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7323,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7323,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7323,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7323,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7323,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7323,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7325,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7325,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7325,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7325,5)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7325,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7325,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7329,42)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7329,42)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7329,42)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7329,42)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7331,42)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7331,42)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7331,42)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7331,42)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7267,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_verify_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7267

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13]
        
    Routine temporaries
        Total         :     778
            Global    :     278
            Local     :     500
        Regenerable   :     125
        Spilled       :      84
        
    Routine stack
        Variables     :     264 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      20 [1.06e-01 ~ 0.1%]
        Spills        :     608 bytes*
            Reads     :     141 [3.88e+00 ~ 3.9%]
            Writes    :     101 [1.53e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_VERIFY_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_VERIFY_REAL8_3D) [102] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7345,12)
  -> INLINE: (7377,10) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7389,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7389,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7389,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7389,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7389,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7389,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7389,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7392,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7392,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7392,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7392,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7392,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7392,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7392,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7396,22)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7396,22)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7396,22)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7396,22)
      <Remainder loop for vectorization>
         remark #15301: REMAINDER LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7396,22)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7399,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7399,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7399,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7399,7)
      <Remainder loop for vectorization>
         remark #15301: REMAINDER LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7399,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7401,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7401,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7401,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7401,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7401,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7401,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7401,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7403,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7403,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7403,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7403,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7403,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7403,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7403,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7407,42)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7407,42)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7407,42)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7407,42)
      <Remainder loop for vectorization>
         remark #15301: REMAINDER LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7407,42)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7409,42)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7409,42)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7409,42)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7409,42)
      <Remainder loop for vectorization>
         remark #15301: REMAINDER LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7409,42)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7345,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_verify_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7345

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13]
        
    Routine temporaries
        Total         :     915
            Global    :     362
            Local     :     553
        Regenerable   :     125
        Spilled       :     184
        
    Routine stack
        Variables     :     264 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      20 [2.20e-02 ~ 0.0%]
        Spills        :    1368 bytes*
            Reads     :     333 [5.21e+00 ~ 5.2%]
            Writes    :     236 [1.34e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_SET_INFO

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_SET_INFO) [103] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7446,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7446,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_set_info_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7446

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    4[ rax rdx rsi rdi]
        
    Routine temporaries
        Total         :      23
            Global    :       8
            Local     :      15
        Regenerable   :      10
        Spilled       :       0
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_INQ_ATTNAME

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_INQ_ATTNAME) [104] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7466,12)
  -> INLINE: (7475,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7476,10) CISM_PARALLEL::BROADCAST_CHARACTER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7466,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_inq_attname_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7466

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   10[ rax rdx rcx rbx rsi rdi r8-r10 r12]
        
    Routine temporaries
        Total         :      51
            Global    :      14
            Local     :      37
        Regenerable   :      23
        Spilled       :       2
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       1 [2.02e+00 ~ 2.0%]
            Writes    :       4 [6.85e+00 ~ 6.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_INQ_DIMID

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_INQ_DIMID) [105] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7482,12)
  -> INLINE: (7490,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7491,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7482,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_inq_dimid_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7482

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      46
            Global    :      15
            Local     :      31
        Regenerable   :      21
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.43e+00 ~ 2.4%]
            Writes    :       3 [5.83e+00 ~ 5.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_INQ_VARID

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_INQ_VARID) [106] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7497,12)
  -> INLINE: (7505,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7506,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7497,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_inq_varid_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7497

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rbx rsi rdi r8-r10]
        
    Routine temporaries
        Total         :      46
            Global    :      15
            Local     :      31
        Regenerable   :      21
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.43e+00 ~ 2.4%]
            Writes    :       3 [5.83e+00 ~ 5.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_INQUIRE

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_INQUIRE) [107] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7512,12)
  -> INLINE: (7519,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7520,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7512,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_inquire_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7512

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    9[ rax rdx rcx rsi rdi r8-r10 r13]
        
    Routine temporaries
        Total         :      44
            Global    :      13
            Local     :      31
        Regenerable   :      25
        Spilled       :       1
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [2.56e+00 ~ 2.6%]
            Writes    :       3 [5.52e+00 ~ 5.5%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_INQUIRE_DIMENSION

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_INQUIRE_DIMENSION) [108] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7526,12)
  -> INLINE: (7539,13) CISM_PARALLEL::BROADCAST_CHARACTER
  -> INLINE: (7544,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7546,13) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7526,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_inquire_dimension_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7526

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   11[ rax rdx rcx rsi rdi r8-r10 r13-r15]
        
    Routine temporaries
        Total         :      72
            Global    :      18
            Local     :      54
        Regenerable   :      39
        Spilled       :       3
        
    Routine stack
        Variables     :      36 bytes*
            Reads     :       2 [2.33e+00 ~ 2.3%]
            Writes    :       6 [4.45e+00 ~ 4.4%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_INQUIRE_VARIABLE

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_INQUIRE_VARIABLE) [109] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7554,12)
  -> INLINE: (7569,13) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7570,13) CISM_PARALLEL::BROADCAST_CHARACTER
  -> INLINE: (7576,13) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7577,13) CISM_PARALLEL::BROADCAST_INTEGER_1D
  -> INLINE: (7582,10) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7584,13) CISM_PARALLEL::BROADCAST_INTEGER
  -> INLINE: (7588,13) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7577,13)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7577,13)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7577,13)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7577,13)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7577,13)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7577,13)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7577,13)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(455,20) inlined into /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7577,13)
<Remainder, Multiversioned v2>
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7554,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_inquire_variable_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7554

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     182
            Global    :      53
            Local     :     129
        Regenerable   :      87
        Spilled       :      11
        
    Routine stack
        Variables     :      76 bytes*
            Reads     :       6 [1.08e+00 ~ 1.1%]
            Writes    :      12 [3.24e+00 ~ 3.2%]
        Spills        :      48 bytes*
            Reads     :      23 [2.79e+00 ~ 2.8%]
            Writes    :       8 [1.67e+00 ~ 1.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_OPEN

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_OPEN) [110] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7596,12)
  -> INLINE: (7604,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7596,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_open_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7596

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      39
            Global    :      12
            Local     :      27
        Regenerable   :      17
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.18e+00 ~ 3.2%]
            Writes    :       2 [4.46e+00 ~ 4.5%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PRINT_ALL

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PRINT_ALL) [111] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7610,14)
  -> INLINE: (7631,13) CISM_PARALLEL::PARALLEL_BARRIER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7634,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7635,14)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7636,17)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7636,17)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7643,5)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7610,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_print_all_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7610

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     145
            Global    :      59
            Local     :      86
        Regenerable   :      78
        Spilled       :      30
        
    Routine stack
        Variables     :     204 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      24 [6.09e+00 ~ 6.1%]
        Spills        :     208 bytes*
            Reads     :      31 [1.21e+01 ~ 12.1%]
            Writes    :      26 [1.95e+00 ~ 2.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PRINT_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PRINT_INTEGER_2D) [112] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7653,14)
  -> INLINE: (7677,10) CISM_PARALLEL::PARALLEL_BARRIER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7668,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7669,11)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (7670:14) and at (7670:14)
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7653,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_print_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7653

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   12[ rax rdx rcx rbx rsi rdi r8-r9 r12-r15]
        
    Routine temporaries
        Total         :      98
            Global    :      35
            Local     :      63
        Regenerable   :      61
        Spilled       :      10
        
    Routine stack
        Variables     :     212 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      23 [1.39e+01 ~ 13.9%]
        Spills        :      48 bytes*
            Reads     :       7 [5.45e+00 ~ 5.5%]
            Writes    :       6 [1.83e+00 ~ 1.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PRINT_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PRINT_REAL8_2D) [113] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7684,14)
  -> INLINE: (7707,10) CISM_PARALLEL::PARALLEL_BARRIER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7698,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7699,11)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization. First dependence is shown below. Use level 5 report for details
      remark #15346: vector dependence: assumed OUTPUT dependence between at (7700:14) and at (7700:14)
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7684,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_print_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7684

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   12[ rax rdx rcx rbx rsi rdi r8-r9 r12-r15]
        
    Routine temporaries
        Total         :      98
            Global    :      35
            Local     :      63
        Regenerable   :      61
        Spilled       :      10
        
    Routine stack
        Variables     :     212 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      23 [1.39e+01 ~ 13.9%]
        Spills        :      48 bytes*
            Reads     :       7 [5.45e+00 ~ 5.5%]
            Writes    :       6 [1.83e+00 ~ 1.8%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PRINT_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PRINT_REAL8_3D) [114] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7712,14)
  -> INLINE: (7735,10) CISM_PARALLEL::PARALLEL_BARRIER


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7726,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7727,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7728,14)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7728,14)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7712,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_print_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7712

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     130
            Global    :      55
            Local     :      75
        Regenerable   :      63
        Spilled       :      23
        
    Routine stack
        Variables     :     220 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      24 [6.25e+00 ~ 6.3%]
        Spills        :     152 bytes*
            Reads     :      22 [1.04e+01 ~ 10.4%]
            Writes    :      19 [1.94e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_ATT_CHARACTER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_ATT_CHARACTER) [115] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7743,12)
  -> INLINE: (7751,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7743,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_att_character_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7743

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      42
            Global    :      14
            Local     :      28
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.36e+00 ~ 3.4%]
            Writes    :       2 [4.70e+00 ~ 4.7%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_ATT_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_ATT_INTEGER) [116] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7756,12)
  -> INLINE: (7765,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7756,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_att_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7756

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      39
            Global    :      13
            Local     :      26
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.47e+00 ~ 3.5%]
            Writes    :       2 [4.86e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_ATT_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_ATT_REAL4) [117] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7770,12)
  -> INLINE: (7779,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7770,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_att_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7770

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      39
            Global    :      13
            Local     :      26
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.47e+00 ~ 3.5%]
            Writes    :       2 [4.86e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_ATT_REAL4_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_ATT_REAL4_1D) [118] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7784,12)
  -> INLINE: (7793,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7784,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_att_real4_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7784

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      39
            Global    :      13
            Local     :      26
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.47e+00 ~ 3.5%]
            Writes    :       2 [4.86e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_ATT_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_ATT_REAL8) [119] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7798,12)
  -> INLINE: (7807,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7798,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_att_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7798

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      39
            Global    :      13
            Local     :      26
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.47e+00 ~ 3.5%]
            Writes    :       2 [4.86e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_ATT_REAL8_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_ATT_REAL8_1D) [120] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7812,12)
  -> INLINE: (7821,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7812,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_att_real8_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7812

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      39
            Global    :      13
            Local     :      26
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.47e+00 ~ 3.5%]
            Writes    :       2 [4.86e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_VAR_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_VAR_INTEGER) [121] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7829,12)
  -> INLINE: (7844,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7829,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_var_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7829

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      42
            Global    :      14
            Local     :      28
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.47e+00 ~ 3.5%]
            Writes    :       3 [4.85e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_VAR_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_VAR_REAL4) [122] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7849,12)
  -> INLINE: (7864,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7849,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_var_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7849

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      42
            Global    :      14
            Local     :      28
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.47e+00 ~ 3.5%]
            Writes    :       3 [4.85e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_VAR_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_VAR_REAL8) [123] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7869,12)
  -> INLINE: (7884,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7869,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_var_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7869

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      42
            Global    :      14
            Local     :      28
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.47e+00 ~ 3.5%]
            Writes    :       3 [4.85e+00 ~ 4.9%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_PUT_VAR_REAL8_1D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_PUT_VAR_REAL8_1D) [124] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7889,12)
  -> INLINE: (7904,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7889,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_put_var_real8_1d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7889

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      46
            Global    :      14
            Local     :      32
        Regenerable   :      18
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.24e+00 ~ 3.2%]
            Writes    :       3 [4.54e+00 ~ 4.5%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDEF

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDEF) [125] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7910,12)
  -> INLINE: (7917,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7910,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_redef_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7910

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      27
            Global    :       9
            Local     :      18
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [4.11e+00 ~ 4.1%]
            Writes    :       2 [4.76e+00 ~ 4.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_SUM_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_SUM_INTEGER) [126] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7925,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7925,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_sum_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7925

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_SUM_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_SUM_REAL4) [127] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7942,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7942,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_sum_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7942

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    8[ rax rdx rcx rsi rdi r8-r9 zmm0]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_SUM_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_SUM_REAL8) [128] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7959,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7959,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_sum_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7959

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    8[ rax rdx rcx rsi rdi r8-r9 zmm0]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_SUM_INTEGER_NVAR

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_SUM_INTEGER_NVAR) [129] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7976,12)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7987,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7987,5)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7987,5)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7987,5)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7989,5)
   remark #25399: memcopy generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7989,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7989,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7989,5):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7976,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_sum_integer_nvar_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7976

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   14[ rax rdx rcx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :      63
            Global    :      30
            Local     :      33
        Regenerable   :      11
        Spilled       :       4
        
    Routine stack
        Variables     :       8 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       1 [5.31e-01 ~ 0.5%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_SUM_REAL8_NVAR

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_SUM_REAL8_NVAR) [130] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7994,12)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8005,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8005,5)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8005,5)
<Multiversioned v2>
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8005,5)
<Remainder loop for vectorization, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8007,5)
   remark #25399: memcopy generated
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8007,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8007,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8007,5):remark #34026: call to memcpy implemented as a call to optimized library version
/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7994,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_sum_real8_nvar_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7994

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   14[ rax rdx rcx rbx rsi rdi r8-r14 zmm0]
        
    Routine temporaries
        Total         :      59
            Global    :      27
            Local     :      32
        Regenerable   :      11
        Spilled       :       4
        
    Routine stack
        Variables     :       8 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       1 [4.66e-01 ~ 0.5%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MAX_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MAX_INTEGER) [131] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8015,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8015,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_max_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8015

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MAX_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MAX_REAL4) [132] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8032,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8032,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_max_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8032

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    8[ rax rdx rcx rsi rdi r8-r9 zmm0]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MAX_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MAX_REAL8) [133] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8049,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8049,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_max_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8049

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    8[ rax rdx rcx rsi rdi r8-r9 zmm0]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MAXLOC_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MAXLOC_INTEGER) [134] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8069,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8069,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_maxloc_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8069

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   11[ rax rdx rcx rsi rdi r8-r11 r13-r14]
        
    Routine temporaries
        Total         :      30
            Global    :       8
            Local     :      22
        Regenerable   :      14
        Spilled       :       2
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MAXLOC_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MAXLOC_REAL4) [135] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8090,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8090,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_maxloc_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8090

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   12[ rax rdx rcx rsi rdi r8-r11 r13-r14 zmm0]
        
    Routine temporaries
        Total         :      30
            Global    :       8
            Local     :      22
        Regenerable   :      14
        Spilled       :       2
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MAXLOC_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MAXLOC_REAL8) [136] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8111,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8111,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_maxloc_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8111

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   12[ rax rdx rcx rsi rdi r8-r11 r13-r14 zmm0]
        
    Routine temporaries
        Total         :      30
            Global    :       8
            Local     :      22
        Regenerable   :      14
        Spilled       :       2
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MIN_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MIN_INTEGER) [137] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8136,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8136,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_min_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8136

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MIN_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MIN_REAL4) [138] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8153,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8153,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_min_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8153

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    8[ rax rdx rcx rsi rdi r8-r9 zmm0]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MIN_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MIN_REAL8) [139] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8170,12)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8170,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_min_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8170

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    8[ rax rdx rcx rsi rdi r8-r9 zmm0]
        
    Routine temporaries
        Total         :      25
            Global    :       6
            Local     :      19
        Regenerable   :      14
        Spilled       :       0
        
    Routine stack
        Variables     :      20 bytes*
            Reads     :       1 [3.85e+00 ~ 3.8%]
            Writes    :       1 [3.85e+00 ~ 3.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MINLOC_INTEGER

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MINLOC_INTEGER) [140] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8190,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8190,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_minloc_integer_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8190

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   11[ rax rdx rcx rsi rdi r8-r11 r13-r14]
        
    Routine temporaries
        Total         :      30
            Global    :       8
            Local     :      22
        Regenerable   :      14
        Spilled       :       2
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MINLOC_REAL4

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MINLOC_REAL4) [141] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8211,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8211,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_minloc_real4_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8211

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   12[ rax rdx rcx rsi rdi r8-r11 r13-r14 zmm0]
        
    Routine temporaries
        Total         :      30
            Global    :       8
            Local     :      22
        Regenerable   :      14
        Spilled       :       2
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_REDUCE_MINLOC_REAL8

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_REDUCE_MINLOC_REAL8) [142] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8232,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8232,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_reduce_minloc_real8_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8232

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   12[ rax rdx rcx rsi rdi r8-r11 r13-r14 zmm0]
        
    Routine temporaries
        Total         :      30
            Global    :       8
            Local     :      22
        Regenerable   :      14
        Spilled       :       2
        
    Routine stack
        Variables     :       4 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_SHOW_MINMAX

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_SHOW_MINMAX) [143] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8254,14)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13)
         remark #25084: Preprocess Loopnests: Moving Out Store    [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13) ]
         remark #15331: loop was not vectorized: precise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model
         remark #25439: unrolled with remainder by 8  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13)
      <Remainder>
         remark #25436: completely unrolled by 7  
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13)
         remark #25084: Preprocess Loopnests: Moving Out Store    [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13) ]
         remark #15331: loop was not vectorized: precise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model
         remark #25439: unrolled with remainder by 8  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8265,13)
      <Remainder>
         remark #25436: completely unrolled by 7  
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13)
         remark #25084: Preprocess Loopnests: Moving Out Store    [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13) ]
         remark #15331: loop was not vectorized: precise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model
         remark #25439: unrolled with remainder by 8  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13)
      <Remainder>
         remark #25436: completely unrolled by 7  
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13)
         remark #25084: Preprocess Loopnests: Moving Out Store    [ /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13) ]
         remark #15331: loop was not vectorized: precise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model
         remark #25439: unrolled with remainder by 8  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8267,13)
      <Remainder>
         remark #25436: completely unrolled by 7  
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8254,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_show_minmax_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8254

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   21[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm6]
        
    Routine temporaries
        Total         :     341
            Global    :     108
            Local     :     233
        Regenerable   :      48
        Spilled       :      72
        
    Routine stack
        Variables     :     132 bytes*
            Reads     :       2 [3.82e-02 ~ 0.0%]
            Writes    :       9 [1.89e-01 ~ 0.2%]
        Spills        :     520 bytes*
            Reads     :     116 [1.08e+01 ~ 10.8%]
            Writes    :      81 [2.71e+00 ~ 2.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_SYNC

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_SYNC) [144] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8295,12)
  -> INLINE: (8302,10) CISM_PARALLEL::BROADCAST_INTEGER


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8295,12):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_sync_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8295

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    7[ rax rdx rcx rsi rdi r8-r9]
        
    Routine temporaries
        Total         :      27
            Global    :       9
            Local     :      18
        Regenerable   :      13
        Spilled       :       0
        
    Routine stack
        Variables     :      12 bytes*
            Reads     :       1 [4.11e+00 ~ 4.1%]
            Writes    :       2 [4.76e+00 ~ 4.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::STAGGERED_NO_PENETRATION_MASK

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::STAGGERED_NO_PENETRATION_MASK) [145] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8308,14)
  -> (8347,10) CISM_PARALLEL::STAGGERED_PARALLEL_HALO_INTEGER_2D
  -> (8348,10) CISM_PARALLEL::STAGGERED_PARALLEL_HALO_INTEGER_2D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8324,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8324,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8324,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8324,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8324,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8324,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8325,5)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8325,5)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8325,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8325,5)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8325,5)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8325,5)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8329,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8329,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8329,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8329,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8329,8)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8329,8)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8334,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8334,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8334,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8334,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8334,8)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8334,8)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8339,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8339,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8339,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8339,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8339,8)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8339,8)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8344,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8344,8)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8344,8)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8344,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8344,8)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8344,8)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8308,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_staggered_no_penetration_mask_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8308

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     179
            Global    :     138
            Local     :      41
        Regenerable   :      16
        Spilled       :      21
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :     120 bytes*
            Reads     :      46 [9.64e-01 ~ 1.0%]
            Writes    :      39 [2.08e+00 ~ 2.1%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::STAGGERED_PARALLEL_HALO_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::STAGGERED_PARALLEL_HALO_INTEGER_2D) [146] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8403,14)
  -> (8444,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8466,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8466,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8466,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8466,7)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8466,7)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8466,7)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8473,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8473,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8473,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8473,7)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8473,7)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8473,7)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8481,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8481,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8481,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8481,7)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8481,7)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8481,7)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8487,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8487,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8487,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8487,7)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8487,7)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8487,7)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8492,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8492,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8492,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8492,7)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8492,7)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8492,7)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8498,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8498,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8498,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8498,7)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8498,7)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8498,7)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8505,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8505,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8505,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8505,7)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8505,7)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8505,7)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8510,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8510,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8510,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8510,7)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8510,7)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8510,7)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8519,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8519,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8519,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8519,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8519,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8519,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8523,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8523,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8523,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8523,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8523,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8523,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8527,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8527,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8527,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8527,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8527,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8527,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8531,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8531,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8531,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8531,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8531,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8531,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8537,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8537,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8537,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8537,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8537,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8537,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8541,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8541,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8541,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8541,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8541,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8541,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8545,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8545,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8545,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8545,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8545,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8545,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8549,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8549,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8549,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8549,11)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8549,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8549,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8554,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8554,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8554,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8554,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8554,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8554,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8555,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8555,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8555,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8555,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8555,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8555,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8556,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8556,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8556,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8556,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8556,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8556,30)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8558,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8558,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8558,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8558,30)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8558,30)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8558,30)
   <Remainder>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8403,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_staggered_parallel_halo_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8403

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     973
            Global    :     528
            Local     :     445
        Regenerable   :     141
        Spilled       :      82
        
    Routine stack
        Variables     :     132 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      11 [2.50e-01 ~ 0.3%]
        Spills        :     568 bytes*
            Reads     :     167 [4.24e+00 ~ 4.2%]
            Writes    :     124 [1.89e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::STAGGERED_PARALLEL_HALO_INTEGER_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::STAGGERED_PARALLEL_HALO_INTEGER_3D) [147] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8567,14)
  -> (8608,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8630,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8630,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8630,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8630,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8630,7)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8630,7)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8630,7)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8637,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8637,8)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8637,8)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8637,8)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8645,7)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8645,7)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8645,7)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8645,7)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8651,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8651,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8651,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8651,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8651,7)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8651,7)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8651,7)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8656,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8656,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8656,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8656,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8656,7)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8656,7)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8656,7)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8662,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8662,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8662,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8662,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8662,7)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8662,7)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8662,7)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8669,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8669,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8669,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8669,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8669,7)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8669,7)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8669,7)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8674,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8674,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8674,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8674,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8674,7)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8674,7)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8674,7)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8682,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8682,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8682,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8682,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8682,11)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8682,11)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8682,11)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8686,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8686,11)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8686,11)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8686,11)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8690,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8690,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8690,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8690,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8690,11)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8690,11)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8690,11)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8694,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8694,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8694,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8694,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8694,11)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8694,11)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8694,11)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8700,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8700,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8700,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8700,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8700,11)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8700,11)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8700,11)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8704,11)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8704,11)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8704,11)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8704,11)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8708,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8708,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8708,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8708,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8708,11)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8708,11)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8708,11)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8712,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8712,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8712,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8712,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8712,11)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8712,11)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8712,11)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8717,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8717,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8717,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8717,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8717,30)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8717,30)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8717,30)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8718,30)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8718,30)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8718,30)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8718,30)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8719,30)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8719,30)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8719,30)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8719,30)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8721,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8721,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8721,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8721,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8721,30)
   <Multiversioned v2>
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8721,30)
         remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
         remark #25439: unrolled with remainder by 2  
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8721,30)
      <Remainder>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8567,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_staggered_parallel_halo_integer_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8567

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1165
            Global    :     633
            Local     :     532
        Regenerable   :     136
        Spilled       :     272
        
    Routine stack
        Variables     :     132 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      11 [6.03e-02 ~ 0.1%]
        Spills        :    2120 bytes*
            Reads     :     492 [7.15e+00 ~ 7.1%]
            Writes    :     384 [1.86e+00 ~ 1.9%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::STAGGERED_PARALLEL_HALO_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::STAGGERED_PARALLEL_HALO_REAL8_3D) [148] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8893,14)
  -> (8934,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8958,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8958,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8958,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8958,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8958,7)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8958,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8958,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8965,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8965,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8965,8)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8965,8)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8973,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8973,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8973,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8973,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8979,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8979,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8979,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8979,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8979,7)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8979,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8979,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8986,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8986,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8986,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8986,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8986,7)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8986,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8986,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8992,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8992,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8992,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8992,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8992,7)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8992,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8992,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8999,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8999,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8999,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8999,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8999,7)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8999,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8999,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9004,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9004,7)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9004,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9004,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9004,7)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9004,7)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9004,7)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9012,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9012,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9012,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9012,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9012,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9012,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9012,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9016,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9016,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9016,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9016,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9020,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9020,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9020,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9020,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9020,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9020,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9020,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9024,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9024,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9024,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9024,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9024,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9024,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9024,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9030,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9030,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9030,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9030,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9030,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9030,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9030,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9034,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9034,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9034,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9034,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9038,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9038,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9038,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9038,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9038,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9038,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9038,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9042,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9042,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9042,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9042,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9042,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9042,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9042,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9047,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9047,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9047,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9047,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9047,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9047,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9047,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9048,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9048,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9048,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9048,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9049,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9049,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9049,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9049,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9051,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9051,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9051,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9051,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9051,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9051,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9051,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8893,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_staggered_parallel_halo_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8893

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1248
            Global    :     643
            Local     :     605
        Regenerable   :     128
        Spilled       :     311
        
    Routine stack
        Variables     :     132 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      11 [3.75e-02 ~ 0.0%]
        Spills        :    2424 bytes*
            Reads     :     582 [3.44e+00 ~ 3.4%]
            Writes    :     435 [1.47e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::STAGGERED_PARALLEL_HALO_REAL8_4D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::STAGGERED_PARALLEL_HALO_REAL8_4D) [149] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9060,14)
  -> (9101,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9123,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9123,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9123,7)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9123,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9123,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9123,7)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9123,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9123,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9130,8)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9130,8)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9130,8)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9130,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9130,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9130,8)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9130,8)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9130,8)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9138,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9138,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9138,7)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9138,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9138,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9138,7)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9138,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9138,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9144,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9144,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9144,7)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9144,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9144,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9144,7)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9144,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9144,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9149,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9149,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9149,7)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9149,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9149,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9149,7)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9149,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9149,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9155,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9155,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9155,7)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9155,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9155,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9155,7)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9155,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9155,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9162,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9162,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9162,7)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9162,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9162,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9162,7)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9162,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9162,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9167,7)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9167,7)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9167,7)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9167,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9167,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9167,7)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9167,7)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9167,7)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9175,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9175,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9175,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9175,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9175,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9175,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9175,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9175,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9179,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9179,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9179,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9179,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9179,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9179,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9179,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9179,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9183,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9183,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9183,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9183,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9183,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9183,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9183,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9183,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9187,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9187,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9187,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9187,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9187,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9187,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9187,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9187,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9193,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9193,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9193,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9193,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9193,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9193,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9193,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9193,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9197,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9197,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9197,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9197,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9197,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9197,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9197,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9197,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9201,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9201,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9201,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9201,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9201,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9201,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9201,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9201,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9205,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9205,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9205,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9205,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9205,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9205,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9205,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9205,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9210,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9210,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9210,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9210,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9210,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9210,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9210,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9210,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9211,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9211,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9211,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9211,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9211,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9211,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9211,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9211,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9212,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9212,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9212,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9212,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9212,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9212,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9212,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9212,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9214,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9214,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9214,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9214,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9214,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9214,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9214,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9214,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9060,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_staggered_parallel_halo_real8_4d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9060

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1608
            Global    :     755
            Local     :     853
        Regenerable   :     128
        Spilled       :     420
        
    Routine stack
        Variables     :     132 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      11 [8.05e-03 ~ 0.0%]
        Spills        :    3296 bytes*
            Reads     :     775 [3.21e+00 ~ 3.2%]
            Writes    :     551 [1.43e+00 ~ 1.4%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::FC_GATHERV_INT

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::FC_GATHERV_INT) [150] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9527,15)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9608,10)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9608,10)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9631,34)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9631,34)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9631,34)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9631,34)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9631,44)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9631,44)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9631,44)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9631,44)
<Remainder, Multiversioned v2>
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9604,10)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9615,10)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9527,15):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_fc_gatherv_int_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9527

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     196
            Global    :      78
            Local     :     118
        Regenerable   :      53
        Spilled       :      16
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       4 [4.63e-01 ~ 0.5%]
            Writes    :       5 [7.54e-01 ~ 0.8%]
        Spills        :      88 bytes*
            Reads     :      14 [2.49e+00 ~ 2.5%]
            Writes    :      12 [1.28e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::FC_GATHERV_LOG

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::FC_GATHERV_LOG) [151] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9926,15)


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10007,10)
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10007,10)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10030,34)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10030,34)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10030,34)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10030,34)
<Remainder, Multiversioned v2>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10030,44)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15300: LOOP WAS VECTORIZED
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10030,44)
<Remainder loop for vectorization, Multiversioned v1>
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10030,44)
<Multiversioned v2>
   remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   remark #25439: unrolled with remainder by 2  
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10030,44)
<Remainder, Multiversioned v2>
LOOP END


Non-optimizable loops:


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10003,10)
   remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(10014,10)
   remark #15543: loop was not vectorized: loop with function call not considered an optimization candidate.
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9926,15):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_fc_gatherv_log_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9926

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     196
            Global    :      78
            Local     :     118
        Regenerable   :      53
        Spilled       :      16
        
    Routine stack
        Variables     :      24 bytes*
            Reads     :       4 [4.63e-01 ~ 0.5%]
            Writes    :       5 [7.54e-01 ~ 0.8%]
        Spills        :      88 bytes*
            Reads     :      14 [2.49e+00 ~ 2.5%]
            Writes    :      12 [1.28e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::STAGGERED_PARALLEL_HALO_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::STAGGERED_PARALLEL_HALO_REAL8_2D) [152] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8730,14)
  -> (8771,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8793,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8793,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8793,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8793,7)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8793,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8793,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8800,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8800,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8800,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8800,7)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8800,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8800,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8808,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8808,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8808,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8808,7)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8808,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8808,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8814,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8814,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8814,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8814,7)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8814,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8814,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8819,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8819,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8819,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8819,7)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8819,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8819,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8825,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8825,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8825,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8825,7)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8825,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8825,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8832,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8832,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8832,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8832,7)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8832,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8832,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8837,7)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8837,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8837,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8837,7)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8837,7)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8837,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8845,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8845,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8845,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8845,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8845,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8845,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8849,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8849,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8849,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8849,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8849,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8849,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8853,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8853,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8853,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8853,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8853,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8853,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8857,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8857,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8857,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8857,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8857,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8857,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8863,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8863,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8863,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8863,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8863,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8863,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8867,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8867,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8867,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8867,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8867,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8867,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8871,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8871,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8871,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8871,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8871,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8871,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8875,11)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8875,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8875,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8875,11)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8875,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8875,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8880,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8880,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8880,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8880,30)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8880,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8880,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8881,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8881,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8881,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8881,30)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8881,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8881,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8882,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8882,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8882,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8882,30)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8882,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8882,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8884,30)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8884,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8884,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8884,30)
<Multiversioned v2>
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8884,30)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8884,30)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8730,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_staggered_parallel_halo_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8730

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1010
            Global    :     510
            Local     :     500
        Regenerable   :     128
        Spilled       :     110
        
    Routine stack
        Variables     :     132 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      11 [1.80e-01 ~ 0.2%]
        Spills        :     792 bytes*
            Reads     :     184 [1.96e+00 ~ 2.0%]
            Writes    :     151 [1.27e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::STAGGERED_PARALLEL_HALO_EXTRAPOLATE_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::STAGGERED_PARALLEL_HALO_EXTRAPOLATE_REAL8_2D) [153] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9295,14)
  -> INLINE: (9316,15) CISM_PARALLEL::PARALLEL_STOP
  -> (9325,10) CISM_PARALLEL::STAGGERED_PARALLEL_HALO_REAL8_2D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9338,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9339,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9339,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9345,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9346,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9346,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9345,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9346,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9346,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9352,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9353,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9353,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9359,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9360,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9360,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9359,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9360,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9360,11)
   <Remainder>
   LOOP END
LOOP END
remark #25050: 
Tempoary Array Elimination (FTAE) Report: 
ftae for the loop at line +9339 /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90
ftae for the loop at line +9353 /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9295,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_staggered_parallel_halo_extrapolate_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9295

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     242
            Global    :     106
            Local     :     136
        Regenerable   :      49
        Spilled       :      27
        
    Routine stack
        Variables     :     204 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      11 [9.64e-02 ~ 0.1%]
        Spills        :     168 bytes*
            Reads     :      30 [5.08e+00 ~ 5.1%]
            Writes    :      30 [3.53e+00 ~ 3.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::STAGGERED_PARALLEL_HALO_EXTRAPOLATE_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::STAGGERED_PARALLEL_HALO_EXTRAPOLATE_INTEGER_2D) [154] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9226,14)
  -> INLINE: (9247,15) CISM_PARALLEL::PARALLEL_STOP
  -> (9256,10) CISM_PARALLEL::STAGGERED_PARALLEL_HALO_INTEGER_2D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9264,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9265,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9265,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9271,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9272,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9272,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9271,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9272,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9272,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9278,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9279,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9279,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9285,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9286,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9286,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9285,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9286,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9286,11)
   <Remainder>
   LOOP END
LOOP END
remark #25050: 
Tempoary Array Elimination (FTAE) Report: 
ftae for the loop at line +9265 /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90
ftae for the loop at line +9279 /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(9226,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_staggered_parallel_halo_extrapolate_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:9226

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     242
            Global    :     106
            Local     :     136
        Regenerable   :      49
        Spilled       :      27
        
    Routine stack
        Variables     :     204 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      11 [9.64e-02 ~ 0.1%]
        Spills        :     168 bytes*
            Reads     :      30 [5.08e+00 ~ 5.1%]
            Writes    :      30 [3.53e+00 ~ 3.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_STOP

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_STOP) [155] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8277,14)


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(8277,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_stop_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:8277

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   10[ rax rdx rcx rsi rdi r8-r9 r13-r15]
        
    Routine temporaries
        Total         :      52
            Global    :      11
            Local     :      41
        Regenerable   :      39
        Spilled       :       3
        
    Routine stack
        Variables     :     124 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       8 [6.78e+00 ~ 6.8%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_INITIALISE

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_INITIALISE) [156] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7427,14)
  -> INLINE: (7437,10) CISM_PARALLEL::PARALLEL_SET_INFO


    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7427,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_initialise_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7427

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    4[ rax rdx rsi rdi]
        
    Routine temporaries
        Total         :      19
            Global    :       8
            Local     :      11
        Regenerable   :      12
        Spilled       :       0
        
    Routine stack
        Variables     :       8 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_TRACERS_REAL8_4D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_TRACERS_REAL8_4D) [157] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7056,14)
  -> (7095,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7108,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7108,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7108,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7108,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7108,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7108,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7108,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7108,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7111,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7111,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7111,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7111,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7111,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7111,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7111,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7111,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7115,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7115,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7115,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7115,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7115,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7115,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7115,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7115,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7117,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7117,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7117,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7117,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7117,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7117,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7117,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7117,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7119,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7119,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7119,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7119,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7119,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7119,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7119,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7119,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7121,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7121,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7121,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7121,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7121,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7121,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7121,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7121,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7125,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7125,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7125,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7125,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7125,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7125,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7125,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7125,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7127,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7127,5)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7127,5)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7127,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7127,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7127,5)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7127,5)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7127,5)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7133,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7133,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7133,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7133,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7133,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7133,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7133,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7133,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7137,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7137,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7137,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7137,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7137,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7137,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7137,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7137,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7141,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7141,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7141,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7141,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7141,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7141,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7141,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7141,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7145,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7145,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7145,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7145,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7145,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7145,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7145,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7145,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7154,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7154,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7154,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7154,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7154,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7154,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7154,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7154,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7158,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7158,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7158,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7158,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7158,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7158,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7158,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7158,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7162,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7162,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7162,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7162,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7162,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7162,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7162,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7162,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7166,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7166,11)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7166,11)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7166,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7166,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7166,11)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7166,11)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7166,11)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7171,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7171,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7171,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7171,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7171,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7171,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7171,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7171,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7172,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7172,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7172,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7172,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7172,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7172,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7172,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7172,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7173,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7173,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7173,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7173,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7173,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7173,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7173,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7173,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7174,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7174,30)
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7174,30)
      <Multiversioned v1>
         remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7174,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7174,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7174,30)
      <Multiversioned v2>
         remark #15542: loop was not vectorized: inner loop was already vectorized

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7174,30)
            remark #15300: LOOP WAS VECTORIZED
         LOOP END

         LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7174,30)
         <Remainder loop for vectorization>
         LOOP END
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7056,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_tracers_real8_4d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:7056

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1503
            Global    :     739
            Local     :     764
        Regenerable   :     148
        Spilled       :     416
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      27 [2.17e-02 ~ 0.0%]
        Spills        :    3224 bytes*
            Reads     :     932 [3.39e+00 ~ 3.4%]
            Writes    :     659 [1.52e+00 ~ 1.5%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_TRACERS_REAL8_3D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_TRACERS_REAL8_3D) [158] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6930,14)
  -> (6969,15) CISM_PARALLEL::PARALLEL_STOP


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6982,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6982,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6982,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6982,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6982,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6982,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6982,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6985,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6985,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6985,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6985,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6985,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6985,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6985,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6989,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6989,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6989,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6989,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6989,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6989,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6989,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6991,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6991,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6991,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6991,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6991,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6991,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6991,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6993,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6993,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6993,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6993,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6993,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6993,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6993,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6995,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6995,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6995,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6995,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6995,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6995,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6995,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6999,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6999,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6999,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6999,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6999,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6999,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6999,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7001,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7001,5)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7001,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7001,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7001,5)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7001,5)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7001,5)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7007,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7007,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7007,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7007,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7007,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7007,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7007,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7011,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7011,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7011,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7011,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7011,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7011,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7011,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7015,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7015,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7015,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7015,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7015,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7015,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7015,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7019,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7019,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7019,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7019,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7019,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7019,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7019,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7028,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7028,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7028,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7028,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7028,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7028,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7028,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7032,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7032,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7032,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7032,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7032,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7032,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7032,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7036,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7036,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7036,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7036,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7036,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7036,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7036,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7040,11)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7040,11)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7040,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7040,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7040,11)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7040,11)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7040,11)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7045,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7045,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7045,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7045,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7045,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7045,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7045,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7046,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7046,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7046,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7046,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7046,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7046,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7046,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7047,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7047,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7047,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7047,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7047,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7047,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7047,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7048,30)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7048,30)
   <Multiversioned v1>
      remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7048,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7048,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7048,30)
   <Multiversioned v2>
      remark #15542: loop was not vectorized: inner loop was already vectorized

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7048,30)
         remark #15300: LOOP WAS VECTORIZED
      LOOP END

      LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(7048,30)
      <Remainder loop for vectorization>
      LOOP END
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6930,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_tracers_real8_3d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6930

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :    1214
            Global    :     663
            Local     :     551
        Regenerable   :     140
        Spilled       :     326
        
    Routine stack
        Variables     :     236 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :      24 [9.63e-02 ~ 0.1%]
        Spills        :    2528 bytes*
            Reads     :     769 [3.51e+00 ~ 3.5%]
            Writes    :     534 [1.34e+00 ~ 1.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_EXTRAPOLATE_REAL8_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_EXTRAPOLATE_REAL8_2D) [159] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6862,14)
  -> (6881,10) CISM_PARALLEL::PARALLEL_HALO_REAL8_2D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6891,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6892,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6892,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6898,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6899,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6899,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6898,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6899,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6899,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6905,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6906,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6906,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6912,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6913,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6913,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6912,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6913,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6913,11)
   <Remainder>
   LOOP END
LOOP END
remark #25050: 
Tempoary Array Elimination (FTAE) Report: 
ftae for the loop at line +6892 /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90
ftae for the loop at line +6906 /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6862,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_extrapolate_real8_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6862

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     191
            Global    :     108
            Local     :      83
        Regenerable   :       8
        Spilled       :      26
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :     160 bytes*
            Reads     :      30 [5.26e+00 ~ 5.3%]
            Writes    :      30 [3.66e+00 ~ 3.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: CISM_PARALLEL::PARALLEL_HALO_EXTRAPOLATE_INTEGER_2D

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (CISM_PARALLEL::PARALLEL_HALO_EXTRAPOLATE_INTEGER_2D) [160] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6797,14)
  -> (6816,10) CISM_PARALLEL::PARALLEL_HALO_INTEGER_2D


    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6826,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6827,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6827,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6833,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6834,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6834,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6833,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6834,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6834,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6840,8)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6841,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6841,11)
   <Remainder>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6847,8)
<Multiversioned v1>
   remark #25233: Loop multiversioned for stride tests on Assumed shape arrays
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6848,11)
      remark #15300: LOOP WAS VECTORIZED
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6848,11)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6847,8)
<Multiversioned v2>
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6848,11)
      remark #15335: loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
      remark #25439: unrolled with remainder by 2  
   LOOP END

   LOOP BEGIN at /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6848,11)
   <Remainder>
   LOOP END
LOOP END
remark #25050: 
Tempoary Array Elimination (FTAE) Report: 
ftae for the loop at line +6827 /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90
ftae for the loop at line +6841 /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90

    Report from: Code generation optimizations [cg]

/glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90(6797,14):remark #34051: REGISTER ALLOCATION : [cism_parallel_mp_parallel_halo_extrapolate_integer_2d_] /glade/u/home/tvda/CISM/libglimmer/parallel_mpi.F90:6797

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   39[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm15]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   15[ rax rdx rcx rbx rsi rdi r8-r15 zmm0]
        
    Routine temporaries
        Total         :     189
            Global    :     108
            Local     :      81
        Regenerable   :       6
        Spilled       :      26
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :     160 bytes*
            Reads     :      30 [5.27e+00 ~ 5.3%]
            Writes    :      30 [3.67e+00 ~ 3.7%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================
